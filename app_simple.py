import streamlit as st
import sys
import os
import logging
import requests
import json
from typing import List, Dict, Any
import time
import random
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
from config import get_config
from src.services.llm_service import OllamaLLMService as SimpleOllamaLLM
from src.services.embedding_service import OllamaEmbeddingService as OllamaEmbeddingClient
from src.services.retrieval_service import RetrievalService

# å°è¯•å¯¼å…¥çœŸå®çš„RAGç³»ç»Ÿç»„ä»¶
REAL_RAG_AVAILABLE = True
try:
    # ä½¿ç”¨æ–°çš„RetrievalService
    if 'import_logged' not in st.session_state:
        logger.info("æ–°çš„æ£€ç´¢æœåŠ¡ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        st.session_state.import_logged = True
except ImportError as e:
    REAL_RAG_AVAILABLE = False
    logger.warning(f"æ£€ç´¢æœåŠ¡ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")

# å°è¯•å¯¼å…¥ç®€åŒ–çš„RAGç»„ä»¶ï¼ˆé¿å…Weaviateä¾èµ–ï¼‰
try:
    # å…ˆå°è¯•å¯¼å…¥Neo4jç›¸å…³ç»„ä»¶
    from src.knowledge.intent_recognition_neo4j import KnowledgeGraphBuilder
    from py2neo import Graph
    SIMPLE_RAG_AVAILABLE = True
    if 'simple_import_logged' not in st.session_state:
        logger.info("ç®€åŒ–RAGç³»ç»Ÿç»„ä»¶å¯¼å…¥æˆåŠŸ")
        st.session_state.simple_import_logged = True
except ImportError as e:
    SIMPLE_RAG_AVAILABLE = False
    logger.warning(f"ç®€åŒ–RAGç³»ç»Ÿç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")

if REAL_RAG_AVAILABLE and 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨æ–°çš„æ£€ç´¢æœåŠ¡è¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True
elif SIMPLE_RAG_AVAILABLE and 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨ç®€åŒ–RAGç³»ç»Ÿè¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True
elif 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿè¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—çŸ¥è¯†RAGç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        border-left: 4px solid #4caf50;
    }
    .system-info {
        background-color: #fff3e0;
        border: 1px solid #ff9800;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .service-status {
        display: flex;
        align-items: center;
        margin: 0.5rem 0;
    }
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    .status-online {
        background-color: #4caf50;
    }
    .status-offline {
        background-color: #f44336;
    }
</style>
""", unsafe_allow_html=True)

class NewRAGSystem:
    """ä½¿ç”¨æ–°çš„RetrievalServiceçš„RAGç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–°çš„RAGç³»ç»Ÿ"""
        self.retrieval_service = None
        self.initialized = False
        
        try:
            if REAL_RAG_AVAILABLE:
                # åˆå§‹åŒ–RetrievalService
                self.retrieval_service = RetrievalService()
                self.initialized = True
                logger.info("æ–°çš„RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("æ–°çš„RAGç³»ç»Ÿä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"æ–°çš„RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if self.initialized and self.retrieval_service:
            try:
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                stats = self.retrieval_service.get_stats()
                return {
                    "neo4j_nodes": stats.get("neo4j_nodes", 0),
                    "neo4j_relationships": stats.get("neo4j_relationships", 0),
                    "weaviate_entities": stats.get("weaviate_entities", 0),
                    "weaviate_relations": stats.get("weaviate_relations", 0),
                    "status": "æ–°ç‰ˆæœ¬"
                }
            except Exception as e:
                logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                return {
                    "neo4j_nodes": 0,
                    "neo4j_relationships": 0,
                    "weaviate_entities": 0,
                    "weaviate_relations": 0,
                    "error": str(e)
                }
        return {
            "neo4j_nodes": 0,
            "neo4j_relationships": 0,
            "weaviate_entities": 0,
            "weaviate_relations": 0,
            "status": "æœªåˆå§‹åŒ–"
        }
    
    def search_knowledge(self, query, **kwargs):
        """æœç´¢çŸ¥è¯†"""
        if self.initialized and self.retrieval_service:
            try:
                import time
                start_time = time.time()
                
                # ä½¿ç”¨æ–°çš„æ£€ç´¢æœåŠ¡è¿›è¡Œæœç´¢
                hybrid_result = self.retrieval_service.search_hybrid(query, limit=5)
                
                retrieval_time = time.time() - start_time
                logger.info(f"æ–°æ£€ç´¢æœåŠ¡å®Œæˆï¼Œè€—æ—¶ {retrieval_time:.2f}s")
                
                # è½¬æ¢ç»“æœæ ¼å¼ä»¥å…¼å®¹ç°æœ‰çš„æ˜¾ç¤ºä»£ç 
                entities = []
                relations = []
                
                # å¤„ç†æ··åˆæ£€ç´¢ç»“æœ
                for result in hybrid_result.hybrid_results:
                    # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä»SearchResultå¯¹è±¡è·å–ï¼‰
                    similarity = result.score if hasattr(result, 'score') else None
                    distance = result.distance if hasattr(result, 'distance') else None
                    
                    # ä»metadataè·å–ä¿¡æ¯
                    metadata = result.metadata if hasattr(result, 'metadata') else {}
                    result_type = metadata.get('type', '')
                    name = metadata.get('name', 'N/A')
                    description = metadata.get('description', 'N/A')
                    
                    # è®°å½•è°ƒè¯•ä¿¡æ¯
                    logger.debug(f"å¤„ç†ç»“æœ: type={result_type}, name={name}, similarity={similarity}")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå…³ç³»ç±»å‹
                    if (result_type == 'relation' and 
                        metadata.get('start_entity') and 
                        metadata.get('end_entity')):
                        # è¿™æ˜¯çœŸæ­£çš„å…³ç³»
                        relation = {
                            'description': f"{metadata.get('start_entity', 'N/A')} â†’ {metadata.get('relation_type', 'N/A')} â†’ {metadata.get('end_entity', 'N/A')}",
                            'type': metadata.get('relation_type', 'N/A'),
                            'start_entity': metadata.get('start_entity', 'N/A'),
                            'end_entity': metadata.get('end_entity', 'N/A'),
                            'similarity': f"{similarity:.3f}" if similarity is not None else "N/A"
                        }
                        relations.append(relation)
                    else:
                        # é»˜è®¤ä½œä¸ºå®ä½“å¤„ç†ï¼ˆåŒ…æ‹¬æ‰€æœ‰å…¶ä»–ç±»å‹ï¼‰
                        entity = {
                            'name': name,
                            'type': result_type if result_type else 'entity',
                            'description': description,
                            'similarity': f"{similarity:.3f}" if similarity is not None else "N/A",
                            'distance': distance,
                            'source_text': result.content if hasattr(result, 'content') else '',
                            'metadata': metadata
                        }
                        entities.append(entity)
                
                return {
                    "query": query,
                    "search_results": {
                        "vector_search": {
                            "entities": entities,
                            "relations": relations  # åªåŒ…å«çœŸæ­£çš„å…³ç³»
                        },
                        "graph_search": {
                            "nodes": [],
                            "relationships": [],
                            "total_nodes": 0,
                            "total_relationships": 0
                        },
                        "hybrid_search": {
                            "search_stats": {
                                "vector_entities": len(entities),
                                "vector_relations": len(relations),
                                "graph_nodes": 0,
                                "graph_relationships": 0
                            }
                        }
                    },
                    "retrieval_time": retrieval_time
                }
                
            except Exception as e:
                logger.error(f"çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
                return {
                    "error": str(e),
                    "query": query,
                    "search_results": {}
                }
        else:
            logger.error("æ–°RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
            return {
                "error": "æ–°RAGç³»ç»Ÿæœªåˆå§‹åŒ–",
                "query": query,
                "search_results": {}
            }
    
    def generate_answer(self, query, search_results=None):
        """ç”Ÿæˆç­”æ¡ˆ"""
        if self.initialized and self.retrieval_service:
            try:
                # ä½¿ç”¨æ£€ç´¢æœåŠ¡ç”Ÿæˆç­”æ¡ˆ
                answer = self.retrieval_service.generate_answer(query, search_results)
                return answer
            except Exception as e:
                logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
        else:
            return "æ–°RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"


class SimpleRAGSystem:
    """ç®€åŒ–çš„RAGç³»ç»Ÿï¼Œä»…ä½¿ç”¨Neo4jçŸ¥è¯†å›¾è°±"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®€åŒ–RAGç³»ç»Ÿ"""
        self.kg_builder = None
        self.neo4j_graph = None
        self.vector_processor = None
        self.initialized = False
        
        try:
            if SIMPLE_RAG_AVAILABLE:
                # è·å–é…ç½®
                config = get_config()
                
                # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ„å»ºå™¨
                self.kg_builder = KnowledgeGraphBuilder()
                # åˆå§‹åŒ–Neo4jè¿æ¥
                self.neo4j_graph = Graph(config.neo4j.uri, auth=(config.neo4j.username, config.neo4j.password))
                
                # å°è¯•åˆå§‹åŒ–å‘é‡å¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
                try:
                    from src.knowledge.vector_storage import WeaviateVectorStore, VectorKnowledgeProcessor
                    embedding_client = OllamaEmbeddingClient()
                    vector_store = WeaviateVectorStore()
                    self.vector_processor = VectorKnowledgeProcessor(embedding_client, vector_store)
                    logger.info("å‘é‡å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as ve:
                    logger.warning(f"å‘é‡å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨å›¾è°±æ£€ç´¢: {ve}")
                    self.vector_processor = None
                
                self.initialized = True
                logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("ç®€åŒ–RAGç³»ç»Ÿä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if self.initialized and self.neo4j_graph:
            try:
                # æŸ¥è¯¢Neo4jç»Ÿè®¡ä¿¡æ¯
                node_count = self.neo4j_graph.run("MATCH (n) RETURN count(n) as count").data()[0]['count']
                rel_count = self.neo4j_graph.run("MATCH ()-[r]->() RETURN count(r) as count").data()[0]['count']
                
                return {
                    "neo4j_nodes": node_count,
                    "neo4j_relationships": rel_count,
                    "weaviate_entities": 0,  # ç®€åŒ–ç‰ˆæœ¬ä¸ä½¿ç”¨Weaviate
                    "weaviate_relations": 0,
                    "status": "ç®€åŒ–ç‰ˆæœ¬"
                }
            except Exception as e:
                logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                return {
                    "neo4j_nodes": 0,
                    "neo4j_relationships": 0,
                    "weaviate_entities": 0,
                    "weaviate_relations": 0,
                    "error": str(e)
                }
        return {
            "neo4j_nodes": 0,
            "neo4j_relationships": 0,
            "weaviate_entities": 0,
            "weaviate_relations": 0,
            "status": "æœªåˆå§‹åŒ–"
        }
    
    def search_knowledge(self, query, **kwargs):
        """æœç´¢çŸ¥è¯†"""
        if self.initialized and self.neo4j_graph:
            try:
                import time
                start_time = time.time()
                
                # ä½¿ç”¨Neo4jè¿›è¡Œç®€å•çš„å…³é”®è¯æœç´¢ï¼Œæ”¯æŒä¸­è‹±æ–‡
                search_query = f"""
                MATCH (n)
                WHERE toLower(n.name) CONTAINS toLower('{query}') 
                   OR toLower(toString(n.description)) CONTAINS toLower('{query}')
                   OR toLower(n.name) CONTAINS toLower('parkinson') 
                   OR toLower(toString(n.description)) CONTAINS toLower('parkinson')
                OPTIONAL MATCH (n)-[r]-(m)
                RETURN n, r, m
                LIMIT 20
                """
                
                logger.info(f"æ‰§è¡ŒNeo4jæŸ¥è¯¢: {search_query}")
                results = self.neo4j_graph.run(search_query).data()
                logger.info(f"Neo4jæŸ¥è¯¢è¿”å› {len(results)} æ¡ç»“æœ")
                
                # æ ¼å¼åŒ–ç»“æœ
                nodes = []
                relationships = []
                seen_nodes = set()
                
                for record in results:
                    if record['n']:
                        node = record['n']
                        node_id = id(node)
                        if node_id not in seen_nodes:
                            node_data = dict(node)
                            node_data['labels'] = list(node.labels)
                            nodes.append(node_data)
                            seen_nodes.add(node_id)
                    
                    if record['r'] and record['m']:
                        rel_data = {
                            'type': type(record['r']).__name__,
                            'properties': dict(record['r']),
                            'start_node': dict(record['n']),
                            'end_node': dict(record['m'])
                        }
                        relationships.append(rel_data)
                
                retrieval_time = time.time() - start_time
                logger.info(f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(relationships)} ä¸ªå…³ç³»ï¼Œè€—æ—¶ {retrieval_time:.2f}s")
                
                # å°è¯•å‘é‡æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                vector_entities = []
                vector_relations = []
                hybrid_knowledge = ""
                
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡å­˜å‚¨å¯ç”¨
                    if hasattr(self, 'vector_processor') and self.vector_processor:
                        # ä½¿ç”¨æ··åˆå‘é‡æ£€ç´¢
                        hybrid_results = self.vector_processor.search_knowledge_hybrid(query, limit=5)
                        
                        # æå–å‘é‡æ£€ç´¢ç»“æœ
                        vector_entities = hybrid_results.get('cosine_results', [])
                        vector_relations = hybrid_results.get('euclidean_results', [])
                        
                        # è·å–æ ¼å¼åŒ–çš„çŸ¥è¯†å†…å®¹ç”¨äºæç¤ºè¯
                        hybrid_knowledge = self.vector_processor.get_knowledge_for_prompt(query, limit=5)
                        
                        # è·å–æ£€ç´¢ç»Ÿè®¡
                        retrieval_stats = hybrid_results.get('retrieval_stats', {})
                        logger.info(f"æ··åˆå‘é‡æ£€ç´¢å®Œæˆ: æ€»è®¡ {retrieval_stats.get('total_found', 0)} ä¸ªç‰‡æ®µï¼Œ"
                                  f"ä½™å¼¦ç›¸ä¼¼åº¦ {retrieval_stats.get('cosine_count', 0)} ä¸ªï¼Œ"
                                  f"æ¬§æ°è·ç¦» {retrieval_stats.get('euclidean_count', 0)} ä¸ª")
                    else:
                        logger.info("å‘é‡å­˜å‚¨ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡æ£€ç´¢")
                except Exception as ve:
                    logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {ve}")
                
                return {
                    "query": query,
                    "search_results": {
                        "graph_search": {
                            "nodes": nodes,
                            "relationships": relationships,
                            "total_nodes": len(nodes),
                            "total_relationships": len(relationships)
                        },
                        "vector_search": {
                            "entities": vector_entities,
                            "relations": vector_relations,
                            "hybrid_knowledge": hybrid_knowledge
                        },
                        "hybrid_search": {
                            "search_stats": {
                                "graph_nodes": len(nodes),
                                "graph_relationships": len(relationships),
                                "vector_entities": len(vector_entities),
                                "vector_relations": len(vector_relations),
                                "has_hybrid_knowledge": bool(hybrid_knowledge)
                            }
                        }
                    },
                    "retrieval_time": retrieval_time
                }
                
            except Exception as e:
                logger.error(f"çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
                return {
                    "error": str(e),
                    "query": query,
                    "search_results": {}
                }
        else:
            logger.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–æˆ–Neo4jè¿æ¥å¤±è´¥")
            return {
                "error": "RAGç³»ç»Ÿæœªåˆå§‹åŒ–",
                "query": query,
                "search_results": {}
            }
    
    def generate_answer(self, query, search_results=None):
        """ç”Ÿæˆç­”æ¡ˆ"""
        if self.initialized and self.kg_builder:
            try:
                if search_results and search_results.get("search_results"):
                    # åŸºäºæœç´¢ç»“æœæ„å»ºä¸Šä¸‹æ–‡
                    context_parts = []
                    graph_search = search_results["search_results"].get("graph_search", {})
                    vector_search = search_results["search_results"].get("vector_search", {})
                    
                    # ä¼˜å…ˆä½¿ç”¨æ··åˆå‘é‡æ£€ç´¢çš„çŸ¥è¯†å†…å®¹
                    hybrid_knowledge = vector_search.get("hybrid_knowledge", "")
                    if hybrid_knowledge and hybrid_knowledge != "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å†…å®¹ã€‚":
                        context_parts.append("ğŸ“š å‘é‡æ£€ç´¢çŸ¥è¯†:")
                        context_parts.append(hybrid_knowledge)
                    
                    # æ·»åŠ å›¾è°±æœç´¢ç»“æœ
                    if graph_search.get("nodes"):
                        context_parts.append("\nğŸ” å›¾è°±å®ä½“:")
                        for node in graph_search["nodes"][:3]:  # å‡å°‘æ˜¾ç¤ºæ•°é‡ï¼Œé¿å…è¿‡é•¿
                            name = node.get("name", "æœªçŸ¥")
                            labels = ", ".join(node.get("labels", []))
                            context_parts.append(f"- {name} ({labels})")
                            if node.get("description"):
                                desc = node['description'][:100] + "..." if len(node['description']) > 100 else node['description']
                                context_parts.append(f"  æè¿°: {desc}")
                    
                    if graph_search.get("relationships"):
                        context_parts.append("\nğŸ”— å›¾è°±å…³ç³»:")
                        for rel in graph_search["relationships"][:2]:  # å‡å°‘æ˜¾ç¤ºæ•°é‡
                            start_name = rel.get("start_node", {}).get("name", "æœªçŸ¥")
                            end_name = rel.get("end_node", {}).get("name", "æœªçŸ¥")
                            rel_type = rel.get("type", "ç›¸å…³")
                            context_parts.append(f"- {start_name} â†’ {rel_type} â†’ {end_name}")
                    
                    context = "\n".join(context_parts)
                    
                    # æ„å»ºå¢å¼ºçš„æç¤ºè¯
                    if hybrid_knowledge and hybrid_knowledge != "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å†…å®¹ã€‚":
                        prompt = f"""åŸºäºä»¥ä¸‹åŒ»ç–—çŸ¥è¯†å›ç­”é—®é¢˜ï¼š

é—®é¢˜: {query}

{context}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†å†…å®¹ï¼Œæä¾›å‡†ç¡®ã€ä¸“ä¸šçš„åŒ»ç–—å›ç­”ã€‚é‡ç‚¹å…³æ³¨å‘é‡æ£€ç´¢çš„çŸ¥è¯†å†…å®¹ï¼Œç»“åˆå›¾è°±ä¿¡æ¯è¿›è¡Œè¡¥å……ã€‚å›ç­”è¦æ±‚ï¼š
1. å‡†ç¡®æ€§ï¼šåŸºäºæä¾›çš„çŸ¥è¯†å†…å®¹å›ç­”
2. å®Œæ•´æ€§ï¼šå°½å¯èƒ½å…¨é¢åœ°å›ç­”é—®é¢˜
3. ä¸“ä¸šæ€§ï¼šä½¿ç”¨åŒ»ç–—ä¸“ä¸šæœ¯è¯­ï¼Œä½†è¦é€šä¿—æ˜“æ‡‚
4. å®‰å…¨æ€§ï¼šå¦‚æ¶‰åŠè¯Šæ–­æ²»ç–—ï¼Œè¯·æé†’å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ"""
                    else:
                        prompt = f"""åŸºäºä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

é—®é¢˜: {query}

çŸ¥è¯†æ¥æº:
{context}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼Œæä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜éœ€è¦æ›´å¤šå“ªæ–¹é¢çš„ä¿¡æ¯ã€‚"""
                    
                    # ä½¿ç”¨Ollamaç”Ÿæˆå›ç­”
                    response = self.kg_builder.recognizer.ollama.generate(prompt)
                    return response
                else:
                    # ç›´æ¥å›ç­”
                    prompt = f"è¯·å›ç­”ä»¥ä¸‹åŒ»ç–—ç›¸å…³é—®é¢˜ï¼š{query}\n\nè¯·æä¾›ä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ï¼Œå¦‚æ¶‰åŠè¯Šæ–­æ²»ç–—å»ºè®®ï¼Œè¯·æé†’å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚"
                    response = self.kg_builder.recognizer.ollama.generate(prompt)
                    return response
                    
            except Exception as e:
                logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
        else:
            return "RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"


class RealRAGSystem:
    """çœŸå®çš„RAGç³»ç»ŸåŒ…è£…å™¨"""
    
    def __init__(self):
        self.rag_system = None
        self.rag_chain = None
        self.retriever = None
        self.prompt_template = None
        self.initialized = False
    
    def initialize(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        try:
            if not REAL_RAG_AVAILABLE:
                raise ImportError("çœŸå®RAGç³»ç»Ÿç»„ä»¶ä¸å¯ç”¨")
            
            # åˆå§‹åŒ–ModularRAGSystem
            self.rag_system = ModularRAGSystem()
            
            # åˆ›å»ºRAGé“¾
            self.rag_chain, self.retriever, self.prompt_template = create_rag_chain(self.rag_system)
            
            self.initialized = True
            return True
            
        except Exception as e:
            st.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if not self.initialized or not self.rag_system:
            return {}
        
        try:
            return self.rag_system.get_stats()
        except Exception as e:
            st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def search_knowledge(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        if not self.initialized:
            return {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}},
                'error': 'ç³»ç»Ÿæœªåˆå§‹åŒ–'
            }
        
        try:
            # ä½¿ç”¨ModularRAGSystemçš„æœç´¢åŠŸèƒ½
            start_time = time.time()
            search_result = self.rag_system.search(query)
            retrieval_time = time.time() - start_time
            
            # ä»æœç´¢ç»“æœä¸­æå–æ£€ç´¢è¯¦æƒ…
            details = search_result.get('retrieval_details', {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}}
            })
            
            # æ·»åŠ æ£€ç´¢æ—¶é—´
            if 'hybrid_results' not in details:
                details['hybrid_results'] = {}
            if 'search_stats' not in details['hybrid_results']:
                details['hybrid_results']['search_stats'] = {}
            details['hybrid_results']['search_stats']['total_time'] = retrieval_time
            
            return details
            
        except Exception as e:
            st.error(f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}")
            return {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}},
                'error': str(e)
            }
    
    def generate_answer(self, query: str) -> str:
        """ç”Ÿæˆå›ç­”"""
        if not self.initialized:
            return "RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚"
        
        try:
            # ä½¿ç”¨ModularRAGSystemçš„æœç´¢åŠŸèƒ½è·å–å®Œæ•´ç»“æœ
            search_result = self.rag_system.search(query)
            answer = search_result.get('answer', 'æ— æ³•ç”Ÿæˆå›ç­”')
            return answer
            
        except Exception as e:
            st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}")
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"
    
    def close(self):
        """å…³é—­RAGç³»ç»Ÿ"""
        if self.rag_system:
            try:
                self.rag_system.close()
            except:
                pass

class MockRAGRetriever:
    """æ¨¡æ‹ŸRAGæ£€ç´¢å™¨ï¼Œç”¨äºå±•ç¤ºæ£€ç´¢è¿‡ç¨‹"""
    
    def __init__(self):
        # æ¨¡æ‹ŸçŸ¥è¯†åº“
        self.knowledge_base = {
            "å¸•é‡‘æ£®ç—…": {
                "symptoms": ["é™æ­¢æ€§éœ‡é¢¤", "è¿åŠ¨è¿Ÿç¼“", "è‚Œè‚‰åƒµç›´", "å§¿åŠ¿ä¸ç¨³"],
                "causes": ["å¤šå·´èƒºç¥ç»å…ƒé€€åŒ–", "é—ä¼ å› ç´ ", "ç¯å¢ƒå› ç´ "],
                "treatments": ["è¯ç‰©æ²»ç–—", "æ·±éƒ¨è„‘åˆºæ¿€", "åº·å¤è®­ç»ƒ"],
                "source": "åŒ»å­¦æ•™ç§‘ä¹¦ç¬¬12ç‰ˆ"
            },
            "é«˜è¡€å‹": {
                "symptoms": ["å¤´ç—›", "å¤´æ™•", "å¿ƒæ‚¸", "è§†åŠ›æ¨¡ç³Š"],
                "prevention": ["ä½ç›é¥®é£Ÿ", "è§„å¾‹è¿åŠ¨", "æ§åˆ¶ä½“é‡", "æˆ’çƒŸé™é…’"],
                "treatments": ["ACEæŠ‘åˆ¶å‰‚", "åˆ©å°¿å‰‚", "é’™é€šé“é˜»æ»å‰‚"],
                "source": "å¿ƒè¡€ç®¡ç–¾ç—…æŒ‡å—2023"
            },
            "ç³–å°¿ç—…": {
                "types": ["1å‹ç³–å°¿ç—…", "2å‹ç³–å°¿ç—…", "å¦Šå¨ ç³–å°¿ç—…"],
                "diet": ["æ§åˆ¶ç¢³æ°´åŒ–åˆç‰©", "å¢åŠ çº¤ç»´æ‘„å…¥", "å®šæ—¶å®šé‡", "é¿å…é«˜ç³–é£Ÿç‰©"],
                "complications": ["ç³–å°¿ç—…è‚¾ç—…", "ç³–å°¿ç—…è§†ç½‘è†œç—…å˜", "ç³–å°¿ç—…è¶³"],
                "source": "ç³–å°¿ç—…è¯Šç–—æŒ‡å—2023"
            }
        }
    
    def search_knowledge(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸçŸ¥è¯†æ£€ç´¢è¿‡ç¨‹"""
        # æ¨¡æ‹Ÿæ£€ç´¢å»¶è¿Ÿ
        time.sleep(0.5)
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        results = {
            "query": query,
            "vector_results": [],
            "graph_results": [],
            "hybrid_results": [],
            "total_time": round(random.uniform(0.3, 1.2), 2)
        }
        
        # æ¨¡æ‹Ÿå‘é‡æ£€ç´¢
        for disease, info in self.knowledge_base.items():
            if disease in query:
                similarity = round(random.uniform(0.7, 0.95), 3)
                results["vector_results"].append({
                    "entity": disease,
                    "similarity": similarity,
                    "content": str(info),
                    "source": info.get("source", "æœªçŸ¥æ¥æº")
                })
        
        # æ¨¡æ‹Ÿå›¾è°±æ£€ç´¢
        if results["vector_results"]:
            main_entity = results["vector_results"][0]["entity"]
            results["graph_results"] = [
                {"relation": "ç—‡çŠ¶", "entities": self.knowledge_base[main_entity].get("symptoms", [])},
                {"relation": "æ²»ç–—", "entities": self.knowledge_base[main_entity].get("treatments", [])},
            ]
        
        # æ¨¡æ‹Ÿæ··åˆæ£€ç´¢
        results["hybrid_results"] = results["vector_results"][:3]  # å–å‰3ä¸ªç»“æœ
        
        return results
    
    def generate_answer(self, query: str) -> str:
        """æ¨¡æ‹Ÿç”Ÿæˆå›ç­”"""
        # ç®€å•çš„æ¨¡æ‹Ÿå›ç­”
        for disease, info in self.knowledge_base.items():
            if disease in query:
                answer_parts = [f"å…³äº{disease}çš„ä¿¡æ¯ï¼š"]
                
                if "symptoms" in info:
                    answer_parts.append(f"ä¸»è¦ç—‡çŠ¶åŒ…æ‹¬ï¼š{', '.join(info['symptoms'])}")
                
                if "treatments" in info:
                    answer_parts.append(f"æ²»ç–—æ–¹æ³•åŒ…æ‹¬ï¼š{', '.join(info['treatments'])}")
                
                if "prevention" in info:
                    answer_parts.append(f"é¢„é˜²æªæ–½åŒ…æ‹¬ï¼š{', '.join(info['prevention'])}")
                
                answer_parts.append("\næ³¨æ„ï¼šæœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œå¦‚æœ‰ç–‘é—®è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚")
                
                return "\n\n".join(answer_parts)
        
        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³çš„åŒ»ç–—ä¿¡æ¯ã€‚å»ºè®®æ‚¨å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè·å–å‡†ç¡®çš„åŒ»ç–—å»ºè®®ã€‚"

def display_retrieval_process(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºæ£€ç´¢è¿‡ç¨‹è¯¦æƒ… - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ” æ£€ç´¢è¿‡ç¨‹è¯¦æƒ…", expanded=False):
        # æ£€ç´¢ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        hybrid_search = search_results.get('hybrid_search', {})
        search_stats = hybrid_search.get('search_stats', {})
        
        with col1:
            vector_count = len(vector_search.get('entities', [])) + len(vector_search.get('relations', []))
            st.metric("å‘é‡æ£€ç´¢", vector_count)
        
        with col2:
            graph_count = graph_search.get('total_nodes', 0)
            st.metric("å›¾è°±æ£€ç´¢", graph_count)
        
        with col3:
            hybrid_count = search_stats.get('graph_nodes', 0) + search_stats.get('vector_entities', 0)
            st.metric("æ··åˆæ£€ç´¢", hybrid_count)
        
        with col4:
            retrieval_time = retrieval_results.get('retrieval_time', 0)
            if isinstance(retrieval_time, (int, float)):
                st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_time:.2f}s")
            else:
                st.metric("æ£€ç´¢è€—æ—¶", "0.00s")

def display_detailed_results(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºè¯¦ç»†æ£€ç´¢ç»“æœ - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ“Š è¯¦ç»†æ£€ç´¢ç»“æœ", expanded=False):
        # åˆ›å»ºä¸‰ä¸ªæ ‡ç­¾é¡µ
        tab1, tab2, tab3 = st.tabs(["ğŸ” å‘é‡æ£€ç´¢", "ğŸ•¸ï¸ å›¾è°±æ£€ç´¢", "ğŸ”„ æ··åˆæ£€ç´¢"])
        
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        hybrid_search = search_results.get('hybrid_search', {})
        
        with tab1:
            entities = vector_search.get('entities', [])
            relations = vector_search.get('relations', [])
            
            if entities:
                st.write("**å®ä½“ç»“æœ:**")
                for i, entity in enumerate(entities[:5], 1):
                    similarity = entity.get('similarity', 'N/A')
                    name = entity.get('name', 'N/A')
                    description = entity.get('description', 'N/A')
                    
                    # ä½¿ç”¨å®¹å™¨è€Œä¸æ˜¯åµŒå¥—expander
                    with st.container():
                        st.markdown(f"**å®ä½“ {i}: {name}**")
                        st.write(f"ç›¸ä¼¼åº¦: {similarity}")
                        st.write(f"æè¿°: {description}")
                        st.divider()
            
            if relations:
                st.write("**å…³ç³»ç»“æœ:**")
                for i, relation in enumerate(relations[:5], 1):
                    description = relation.get('description', 'N/A')
                    with st.container():
                        st.markdown(f"**å…³ç³» {i}**")
                        st.write(f"æè¿°: {description}")
                        st.divider()
            
            if not entities and not relations:
                st.info("æœªæ‰¾åˆ°ç›¸å…³å‘é‡ç»“æœ")
        
        with tab2:
            nodes = graph_search.get('nodes', [])
            relationships = graph_search.get('relationships', [])
            
            if nodes:
                st.write("**èŠ‚ç‚¹ç»“æœ:**")
                for i, node in enumerate(nodes[:10], 1):  # æ˜¾ç¤ºæ›´å¤šèŠ‚ç‚¹
                    name = node.get('name', 'N/A')
                    description = node.get('description', 'N/A')
                    labels = node.get('labels', [])
                    
                    with st.container():
                        st.markdown(f"**èŠ‚ç‚¹ {i}: {name}**")
                        st.write(f"æ ‡ç­¾: {', '.join(labels)}")
                        st.write(f"æè¿°: {description}")
                        # æ˜¾ç¤ºå…¶ä»–å±æ€§
                        other_props = {k: v for k, v in node.items() 
                                     if k not in ['name', 'description', 'labels']}
                        if other_props:
                            st.write("å…¶ä»–å±æ€§:")
                            for key, value in other_props.items():
                                st.write(f"  - {key}: {value}")
                        st.divider()
            
            if relationships:
                st.write("**å…³ç³»ç»“æœ:**")
                for i, rel in enumerate(relationships[:10], 1):  # æ˜¾ç¤ºæ›´å¤šå…³ç³»
                    rel_type = rel.get('type', 'N/A')
                    start_node = rel.get('start_node', {}).get('name', 'N/A')
                    end_node = rel.get('end_node', {}).get('name', 'N/A')
                    
                    with st.container():
                        st.markdown(f"**å…³ç³» {i}: {rel_type}**")
                        st.write(f"èµ·å§‹èŠ‚ç‚¹: {start_node}")
                        st.write(f"ç»“æŸèŠ‚ç‚¹: {end_node}")
                        if rel.get('properties'):
                            st.write(f"å±æ€§: {rel['properties']}")
                        st.divider()
            
            if not nodes and not relationships:
                st.info("æœªæ‰¾åˆ°ç›¸å…³å›¾è°±ç»“æœ")
        
        with tab3:
            search_stats = hybrid_search.get('search_stats', {})
            
            if search_stats:
                st.write("**æ£€ç´¢ç»Ÿè®¡:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    graph_nodes = search_stats.get('graph_nodes', 0)
                    graph_relationships = search_stats.get('graph_relationships', 0)
                    vector_entities = search_stats.get('vector_entities', 0)
                    vector_relations = search_stats.get('vector_relations', 0)
                    
                    st.metric("å›¾è°±èŠ‚ç‚¹", graph_nodes)
                    st.metric("å›¾è°±å…³ç³»", graph_relationships)
                    
                with col2:
                    st.metric("å‘é‡å®ä½“", vector_entities)
                    st.metric("å‘é‡å…³ç³»", vector_relations)
                    
                    retrieval_time = retrieval_results.get('retrieval_time', 0)
                    if isinstance(retrieval_time, (int, float)):
                        st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_time:.3f}s")
                    else:
                        st.metric("æ£€ç´¢è€—æ—¶", "N/A")
            else:
                st.info("æš‚æ— æ··åˆæ£€ç´¢ç»Ÿè®¡ä¿¡æ¯")

def display_knowledge_sources(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºçŸ¥è¯†æ¥æº - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ“š çŸ¥è¯†æ¥æº", expanded=False):
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        
        sources = []
        seen_sources = set()  # ç”¨äºå»é‡
        
        # æ”¶é›†å‘é‡æ£€ç´¢æ¥æº
        for entity in vector_search.get('entities', []):
            if entity.get('name'):
                source_key = f"vector_entity_{entity.get('name')}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å‘é‡å®ä½“',
                        'name': entity.get('name', 'N/A'),
                        'source': 'Weaviateå‘é‡æ•°æ®åº“',
                        'description': entity.get('description', 'N/A')
                    })
                    seen_sources.add(source_key)
        
        for relation in vector_search.get('relations', []):
            if relation.get('description'):
                desc = relation.get('description', 'N/A')[:50] + '...'
                source_key = f"vector_relation_{desc}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å‘é‡å…³ç³»',
                        'name': desc,
                        'source': 'Weaviateå‘é‡æ•°æ®åº“'
                    })
                    seen_sources.add(source_key)
        
        # æ”¶é›†å›¾è°±æ£€ç´¢æ¥æºï¼ˆå»é‡ï¼‰
        for node in graph_search.get('nodes', []):
            if node.get('name'):
                node_name = node.get('name', 'N/A')
                source_key = f"graph_node_{node_name}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å›¾è°±èŠ‚ç‚¹',
                        'name': node_name,
                        'source': 'Neo4jçŸ¥è¯†å›¾è°±',
                        'description': node.get('description', 'N/A'),
                        'labels': ', '.join(node.get('labels', []))
                    })
                    seen_sources.add(source_key)
        
        for rel in graph_search.get('relationships', []):
            if rel.get('type'):
                start_name = rel.get('start_node', {}).get('name', 'N/A')
                end_name = rel.get('end_node', {}).get('name', 'N/A')
                rel_name = f"{start_name} â†’ {rel.get('type', 'N/A')} â†’ {end_name}"
                source_key = f"graph_relation_{rel_name}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å›¾è°±å…³ç³»',
                        'name': rel_name,
                        'source': 'Neo4jçŸ¥è¯†å›¾è°±'
                    })
                    seen_sources.add(source_key)
        
        if sources:
            for i, source in enumerate(sources[:10], 1):
                # ä½¿ç”¨å®¹å™¨è€Œä¸æ˜¯åµŒå¥—expander
                with st.container():
                    st.markdown(f"**æ¥æº {i}: {source['name']}**")
                    st.write(f"ç±»å‹: {source['type']}")
                    st.write(f"æ•°æ®æº: {source['source']}")
                    if source.get('description') and source['description'] != 'N/A':
                        st.write(f"æè¿°: {source['description']}")
                    if source.get('labels'):
                        st.write(f"æ ‡ç­¾: {source['labels']}")
                    st.divider()
        else:
            st.info("æš‚æ— çŸ¥è¯†æ¥æºä¿¡æ¯")

def check_service_status():
    """æ£€æŸ¥å„æœåŠ¡çŠ¶æ€"""
    services = {
        "Ollama": "http://localhost:11434/api/tags",
        "Neo4j": "http://localhost:7474",  # Neo4j Browserç«¯å£
        "Weaviate": "http://localhost:8080/v1/meta"
    }
    
    status = {}
    for service, url in services.items():
        try:
            response = requests.get(url, timeout=3)
            status[service] = response.status_code == 200
        except:
            status[service] = False
    
    return status

def display_service_status():
    """æ˜¾ç¤ºæœåŠ¡çŠ¶æ€"""
    st.subheader("ğŸ”§ æœåŠ¡çŠ¶æ€")
    
    status = check_service_status()
    
    for service, is_online in status.items():
        status_class = "status-online" if is_online else "status-offline"
        status_text = "åœ¨çº¿" if is_online else "ç¦»çº¿"
        
        st.markdown(f"""
        <div class="service-status">
            <div class="status-indicator {status_class}"></div>
            <strong>{service}</strong>: {status_text}
        </div>
        """, unsafe_allow_html=True)
    
    return status

@st.cache_resource
def initialize_llm():
    """åˆå§‹åŒ–LLMï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    return SimpleOllamaLLM()

@st.cache_resource
def initialize_retriever():
    """åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    logger.info(f"å¼€å§‹åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ŒREAL_RAG_AVAILABLE={REAL_RAG_AVAILABLE}")
    
    if REAL_RAG_AVAILABLE:
        logger.info("å°è¯•åˆå§‹åŒ–æ–°RAGç³»ç»Ÿ")
        rag_system = NewRAGSystem()
        if rag_system.initialized:
            logger.info("æ–°RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return rag_system
        else:
            logger.warning("æ–°RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ç®€åŒ–RAGç³»ç»Ÿ")
            if SIMPLE_RAG_AVAILABLE:
                rag_system = SimpleRAGSystem()
                if rag_system.initialized:
                    logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
                    return rag_system
            logger.warning("æ‰€æœ‰RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            return MockRAGRetriever()
    elif SIMPLE_RAG_AVAILABLE:
        logger.info("å°è¯•åˆå§‹åŒ–ç®€åŒ–RAGç³»ç»Ÿ")
        rag_system = SimpleRAGSystem()
        if rag_system.initialized:
            logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return rag_system
        else:
            logger.warning("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            return MockRAGRetriever()
    else:
        logger.info("ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿ")
        return MockRAGRetriever()

def create_medical_prompt(question: str, retrieval_context: str = "") -> str:
    """åˆ›å»ºåŒ»ç–—é¢†åŸŸçš„æç¤ºè¯"""
    base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·åŸºäºåŒ»å­¦çŸ¥è¯†å’Œæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œç¡®ä¿å›ç­”å‡†ç¡®ã€ä¸“ä¸šä¸”æ˜“äºç†è§£ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}"""
    
    if retrieval_context:
        base_prompt += f"""

å‚è€ƒä¿¡æ¯ï¼š
{retrieval_context}"""
    
    base_prompt += """

è¯·æä¾›è¯¦ç»†çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜
2. ç›¸å…³çš„åŒ»å­¦è§£é‡Š
3. æ³¨æ„äº‹é¡¹æˆ–å»ºè®®

æ³¨æ„ï¼šæœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚

å›ç­”ï¼š"""
    
    return base_prompt

def format_retrieval_context(retrieval_results: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡"""
    context_parts = []
    
    vector_results = retrieval_results.get("vector_results", [])
    for result in vector_results:
        context_parts.append(f"å®ä½“: {result.get('entity', 'N/A')}")
        context_parts.append(f"å†…å®¹: {result.get('content', 'N/A')}")
        context_parts.append(f"æ¥æº: {result.get('source', 'N/A')}")
        context_parts.append("---")
    
    return "\n".join(context_parts)

def main():
    """ä¸»å‡½æ•°"""
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¥ åŒ»ç–—çŸ¥è¯†RAGç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 0.7
    
    if 'max_tokens' not in st.session_state:
        st.session_state.max_tokens = 1000
    
    # ä½¿ç”¨ç¼“å­˜çš„åˆå§‹åŒ–å‡½æ•°ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
    with st.spinner("ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ..."):
        rag_system = initialize_retriever()
        
        # æ˜¾ç¤ºåˆå§‹åŒ–ç»“æœï¼ˆåªåœ¨é¦–æ¬¡åŠ è½½æ—¶æ˜¾ç¤ºï¼‰
        if 'init_message_shown' not in st.session_state:
            if isinstance(rag_system, NewRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… æ–°RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"å‘é‡å®ä½“ {stats.get('vector_entities', 0)} ä¸ª")
                else:
                    st.error("âŒ æ–°RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            elif isinstance(rag_system, SimpleRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"çŠ¶æ€: {stats.get('status', 'æœªçŸ¥')}")
                else:
                    st.error("âŒ ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            elif isinstance(rag_system, RealRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… çœŸå®RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"å‘é‡å®ä½“ {stats.get('vector_entities', 0)} ä¸ª")
                else:
                    st.error("âŒ çœŸå®RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            else:
                st.warning("âš ï¸ ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿ")
            
            st.session_state.init_message_shown = True
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        
        # æœåŠ¡çŠ¶æ€
        service_status = display_service_status()
        
        st.divider()
        
        # æ¨¡å‹è®¾ç½®
        st.header("ğŸ¤– æ¨¡å‹è®¾ç½®")
        model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gemma3:4b", "llama3:8b", "qwen2:7b"],
            index=0
        )
        
        st.session_state.temperature = st.slider(
            "æ¸©åº¦ (åˆ›é€ æ€§)",
            min_value=0.1,
            max_value=1.0,
            value=st.session_state.temperature,
            step=0.1
        )
        
        st.session_state.max_tokens = st.slider(
            "æœ€å¤§è¾“å‡ºé•¿åº¦",
            min_value=100,
            max_value=2000,
            value=st.session_state.max_tokens,
            step=100
        )
        
        st.divider()
        
        # ä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥åŒ»ç–—ç›¸å…³é—®é¢˜
        2. ç³»ç»Ÿå°†æ£€ç´¢ç›¸å…³çŸ¥è¯†å¹¶ç”Ÿæˆä¸“ä¸šå›ç­”
        3. å¯åœ¨ä¾§è¾¹æ è°ƒæ•´æ¨¡å‹å‚æ•°
        4. æŸ¥çœ‹è¯¦ç»†çš„æ£€ç´¢è¿‡ç¨‹å’ŒçŸ¥è¯†æ¥æº
        """)
        
        st.divider()
        
        # ç³»ç»Ÿé…ç½®ä¿¡æ¯ï¼ˆç§»é™¤RAGç³»ç»ŸçŠ¶æ€ï¼‰
        st.header("âš™ï¸ å½“å‰é…ç½®")
        st.info(f"""
        **æ¨¡å‹è®¾ç½®:**
        - æ¨¡å‹: {model_name}
        - æ¸©åº¦: {st.session_state.temperature}
        - æœ€å¤§é•¿åº¦: {st.session_state.max_tokens}
        - æœåŠ¡ç«¯å£: 11434
        """)
        
        st.divider()
        
        # åŠŸèƒ½è¯´æ˜
        st.header("ğŸ” åŠŸèƒ½ç‰¹è‰²")
        st.markdown("""
        - **æ™ºèƒ½æ£€ç´¢**: åŸºäºçŸ¥è¯†å›¾è°±çš„ç²¾å‡†æ£€ç´¢
        - **å¤šç»´åº¦åˆ†æ**: å‘é‡+å›¾è°±+æ··åˆæ£€ç´¢
        - **æ£€ç´¢å¯è§†åŒ–**: è¯¦ç»†å±•ç¤ºæ£€ç´¢è¿‡ç¨‹
        - **ä¸“ä¸šé—®ç­”**: åŸºäºåŒ»ç–—çŸ¥è¯†çš„æ™ºèƒ½å›ç­”
        - **å‚æ•°è°ƒèŠ‚**: å¯è°ƒèŠ‚æ¨¡å‹åˆ›é€ æ€§å’Œé•¿åº¦
        """)
        
        # æ³¨æ„äº‹é¡¹
        st.warning("âš ï¸ æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼ŒåŒ»ç–—å»ºè®®è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ")
    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")
        
        # æ£€æŸ¥Ollamaè¿æ¥
        if not service_status.get("Ollama", False):
            st.error("âŒ OllamaæœåŠ¡æœªè¿æ¥ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            st.stop()
        
        # åˆå§‹åŒ–LLM
        llm = initialize_llm()
        llm.model = model_name
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    with col2:
        st.header("ğŸ”§ åŠŸèƒ½é¢æ¿")
        
        # æ¸…ç©ºèŠå¤©å†å²
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
            st.session_state.messages = []
            st.success("èŠå¤©è®°å½•å·²æ¸…ç©ºï¼")
        
        st.divider()
        
        # ç¤ºä¾‹é—®é¢˜
        st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
        example_questions = [
            "å¸•é‡‘æ£®ç—…çš„ä¸»è¦ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ",
            "é«˜è¡€å‹çš„é¢„é˜²æªæ–½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç³–å°¿ç—…æ‚£è€…çš„é¥®é£Ÿæ³¨æ„äº‹é¡¹ï¼Ÿ",
            "å¦‚ä½•é¢„é˜²å¿ƒè„ç—…ï¼Ÿ",
            "æ„Ÿå†’å’Œæµæ„Ÿçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        for i, question in enumerate(example_questions):
            if st.button(question, key=f"example_{i}"):
                # è®¾ç½®ä¼šè¯çŠ¶æ€æ¥å¤„ç†ç¤ºä¾‹é—®é¢˜
                st.session_state.example_question = question
        
        st.divider()
        
        # ç»Ÿè®¡ä¿¡æ¯
        st.subheader("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
        user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
        assistant_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
        
        st.metric("ç”¨æˆ·æ¶ˆæ¯", user_messages)
        st.metric("AIå›å¤", assistant_messages)
    
    # å¤„ç†ç¤ºä¾‹é—®é¢˜
    if hasattr(st.session_state, 'example_question'):
        prompt = st.session_state.example_question
        del st.session_state.example_question
        
        # å¤„ç†é—®é¢˜çš„é€»è¾‘
        process_user_question(prompt, model_name, st.session_state.temperature, st.session_state.max_tokens)
    
    # ç”¨æˆ·è¾“å…¥ï¼ˆç§»åˆ°columnså¤–é¢ï¼‰
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„åŒ»ç–—ç›¸å…³é—®é¢˜..."):
        process_user_question(prompt, model_name, st.session_state.temperature, st.session_state.max_tokens)

def process_user_question(prompt: str, model_name: str, temperature: float, max_tokens: int):
    """å¤„ç†ç”¨æˆ·é—®é¢˜çš„ç»Ÿä¸€å‡½æ•° - ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ"""
    # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¹¶æ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç«‹å³æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
    with st.chat_message("assistant"):
        # åˆ›å»ºä¸€ä¸ªå®¹å™¨ç”¨äºè‡ªåŠ¨æ»šåŠ¨
        question_container = st.container()
        with question_container:
            # æ·»åŠ ä¸€ä¸ªç©ºçš„å ä½ç¬¦ï¼Œç”¨äºJavaScriptæ»šåŠ¨å®šä½
            st.markdown('<div id="question-anchor"></div>', unsafe_allow_html=True)
        
        # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼æ›´æ–°
        thinking_placeholder = st.empty()
        thinking_placeholder.markdown("ğŸ¤– **æ€è€ƒä¸­...**")
        
        # æ£€æŸ¥Ollamaè¿æ¥ï¼ˆé™é»˜æ£€æŸ¥ï¼‰
        service_status = check_service_status()
        if not service_status.get("Ollama", False):
            thinking_placeholder.error("âŒ OllamaæœåŠ¡æœªè¿æ¥ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            return
        
        # åˆå§‹åŒ–ç»„ä»¶
        llm = initialize_llm()
        llm.model = model_name
        retriever = initialize_retriever()  # ä½¿ç”¨ç¼“å­˜çš„åˆå§‹åŒ–å‡½æ•°
        
        # æ›´æ–°æ€è€ƒçŠ¶æ€
        thinking_placeholder.markdown("ğŸ” **æ­£åœ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†...**")
        
        # æ‰§è¡Œæ£€ç´¢
        try:
            retrieval_results = retriever.search_knowledge(prompt)
            
            # æ›´æ–°æ€è€ƒçŠ¶æ€
            thinking_placeholder.markdown("ğŸ§  **æ­£åœ¨åˆ†ææ£€ç´¢ç»“æœ...**")
            
            # åˆ›å»ºå®Œæ•´å“åº”çš„å ä½ç¬¦
            response_placeholder = st.empty()
            
            # æ„å»ºå®Œæ•´å“åº”å†…å®¹
            with response_placeholder.container():
                # æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹
                display_retrieval_process(retrieval_results)
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                display_detailed_results(retrieval_results)
                
                # æ˜¾ç¤ºçŸ¥è¯†æ¥æº
                display_knowledge_sources(retrieval_results)
                
                # æ›´æ–°æ€è€ƒçŠ¶æ€ä¸ºç”Ÿæˆå›ç­”
                thinking_placeholder.markdown("âœï¸ **æ­£åœ¨ç”Ÿæˆä¸“ä¸šå›ç­”...**")
                
                # ç”Ÿæˆå›ç­”
                if isinstance(retriever, (SimpleRAGSystem, RealRAGSystem)) and hasattr(retriever, 'generate_answer'):
                    # ç®€åŒ–æˆ–çœŸå®RAGç³»ç»Ÿ
                    response = retriever.generate_answer(prompt, retrieval_results)
                else:
                    # æ¨¡æ‹ŸRAGç³»ç»Ÿ - ä½¿ç”¨ç®€å•LLM
                    retrieval_context = format_retrieval_context(retrieval_results)
                    medical_prompt = create_medical_prompt(prompt, retrieval_context)
                    response = llm.generate_response(medical_prompt, temperature, max_tokens)
                
                # æ¸…é™¤æ€è€ƒçŠ¶æ€ï¼Œæ˜¾ç¤ºæœ€ç»ˆå›ç­”
                thinking_placeholder.empty()
                
                # æ˜¾ç¤ºAIå›ç­”
                st.markdown("### ğŸ¤– AIå›ç­”")
                
                # æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ
                answer_placeholder = st.empty()
                
                # åˆ†æ®µæ˜¾ç¤ºå›ç­”ï¼ˆæ¨¡æ‹Ÿæµå¼æ•ˆæœï¼‰
                words = response.split()
                displayed_text = ""
                
                for i, word in enumerate(words):
                    displayed_text += word + " "
                    if i % 3 == 0:  # æ¯3ä¸ªè¯æ›´æ–°ä¸€æ¬¡
                        answer_placeholder.markdown(displayed_text)
                        time.sleep(0.05)  # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹Ÿæµå¼æ•ˆæœ
                
                # æ˜¾ç¤ºå®Œæ•´å›ç­”
                answer_placeholder.markdown(response)
                
                # æ„å»ºå®Œæ•´çš„å†å²è®°å½•
                search_results = retrieval_results.get('search_results', {})
                graph_search = search_results.get('graph_search', {})
                vector_search = search_results.get('vector_search', {})
                
                full_response = f"""### ğŸ” æ£€ç´¢ç»“æœ
- å‘é‡æ£€ç´¢: {len(vector_search.get('entities', []))} ä¸ªå®ä½“
- å›¾è°±æ£€ç´¢: {len(graph_search.get('nodes', []))} ä¸ªèŠ‚ç‚¹
- æ£€ç´¢è€—æ—¶: {retrieval_results.get('retrieval_time', 'N/A')}s

### ğŸ¤– AIå›ç­”
{response}
"""
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
                # æ·»åŠ JavaScriptè‡ªåŠ¨æ»šåŠ¨åˆ°é—®é¢˜ä½ç½®
                st.markdown("""
                <script>
                setTimeout(function() {
                    const anchor = document.getElementById('question-anchor');
                    if (anchor) {
                        anchor.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                }, 100);
                </script>
                """, unsafe_allow_html=True)
                
        except Exception as e:
            thinking_placeholder.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"å¤„ç†ç”¨æˆ·é—®é¢˜æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    main()