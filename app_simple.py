import streamlit as st
import sys
import os
import logging
import requests
import json
from typing import List, Dict, Any
import time
import random
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
from config import get_config
from src.services import SimpleOllamaLLM, OllamaEmbeddingClient
from src.services.retrieval_service import RetrievalService

# å°è¯•å¯¼å…¥çœŸå®çš„RAGç³»ç»Ÿç»„ä»¶
REAL_RAG_AVAILABLE = True
try:
    # ä½¿ç”¨æ–°çš„æ¶æ„ç»„ä»¶
    from src.services.retrieval_service import RetrievalService
    from src.services.neo4j_retrieval_service import GraphRetrievalService
    from src.services.hybrid_retrieval_service import HybridRetrievalService
    from src.services.rag_pipeline import RAGPipeline
    if 'import_logged' not in st.session_state:
        logger.info("æ–°çš„æ··åˆæ£€ç´¢æ¶æ„ç»„ä»¶å¯¼å…¥æˆåŠŸ")
        st.session_state.import_logged = True
except ImportError as e:
    REAL_RAG_AVAILABLE = False
    logger.warning(f"æ··åˆæ£€ç´¢æ¶æ„ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")

# å°è¯•å¯¼å…¥ç®€åŒ–çš„RAGç»„ä»¶ï¼ˆé¿å…Weaviateä¾èµ–ï¼‰
try:
    # å…ˆå°è¯•å¯¼å…¥Neo4jç›¸å…³ç»„ä»¶
    from src.knowledge.intent_recognition_neo4j import KnowledgeGraphBuilder
    from py2neo import Graph
    SIMPLE_RAG_AVAILABLE = True
    if 'simple_import_logged' not in st.session_state:
        logger.info("ç®€åŒ–RAGç³»ç»Ÿç»„ä»¶å¯¼å…¥æˆåŠŸ")
        st.session_state.simple_import_logged = True
except ImportError as e:
    SIMPLE_RAG_AVAILABLE = False
    logger.warning(f"ç®€åŒ–RAGç³»ç»Ÿç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")

if REAL_RAG_AVAILABLE and 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨æ–°çš„æ··åˆæ£€ç´¢æ¶æ„è¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True
elif SIMPLE_RAG_AVAILABLE and 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨ç®€åŒ–RAGç³»ç»Ÿè¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True
elif 'system_type_logged' not in st.session_state:
    logger.info("ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿè¿›è¡Œæ¼”ç¤º")
    st.session_state.system_type_logged = True

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŒ»ç–—çŸ¥è¯†RAGç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        border-left: 4px solid #4caf50;
    }
    .system-info {
        background-color: #fff3e0;
        border: 1px solid #ff9800;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .service-status {
        display: flex;
        align-items: center;
        margin: 0.5rem 0;
    }
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    .status-online {
        background-color: #4caf50;
    }
    .status-offline {
        background-color: #f44336;
    }
</style>
""", unsafe_allow_html=True)

class NewRAGSystem:
    """ä½¿ç”¨æ–°çš„æ··åˆæ£€ç´¢æ¶æ„çš„RAGç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ–°çš„æ··åˆRAGç³»ç»Ÿ"""
        self.document_service = None
        self.graph_service = None
        self.hybrid_service = None
        self.rag_pipeline = None
        self.llm_service = None
        self.initialized = False
        
        try:
            if REAL_RAG_AVAILABLE:
                # åˆå§‹åŒ–LLMæœåŠ¡
                self.llm_service = SimpleOllamaLLM()
                
                # åˆå§‹åŒ–æ–‡æ¡£æ£€ç´¢æœåŠ¡ (Weaviate)
                self.document_service = RetrievalService()
                
                # åˆå§‹åŒ–å›¾è°±æ£€ç´¢æœåŠ¡ (Neo4j)
                config = get_config()
                self.graph_service = GraphRetrievalService(config.neo4j)
                
                # åˆå§‹åŒ–æ··åˆæ£€ç´¢æœåŠ¡
                self.hybrid_service = HybridRetrievalService(
                    document_retrieval_service=self.document_service,
                    graph_retrieval_service=self.graph_service,
                    doc_weight=0.6,
                    graph_weight=0.4
                )
                
                # åˆå§‹åŒ–RAGç®¡é“
                self.rag_pipeline = RAGPipeline(
                    hybrid_retrieval_service=self.hybrid_service,
                    llm_service=self.llm_service,
                    max_context_length=4000,
                    temperature=0.7
                )
                
                self.initialized = True
                logger.info("æ–°çš„æ··åˆRAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("æ–°çš„æ··åˆRAGç³»ç»Ÿä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"æ–°çš„æ··åˆRAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if self.initialized and self.hybrid_service:
            try:
                # è·å–æ··åˆæœåŠ¡ç»Ÿè®¡ä¿¡æ¯
                stats = self.hybrid_service.get_stats()
                doc_stats = stats.get('document_service', {})
                graph_stats = stats.get('graph_service', {})
                
                return {
                    "neo4j_nodes": graph_stats.get("total_nodes", 0),
                    "neo4j_relationships": graph_stats.get("total_relationships", 0),
                    "weaviate_entities": doc_stats.get("total_entities", 0),
                    "weaviate_relations": doc_stats.get("total_relations", 0),
                    "status": "æ··åˆæ¶æ„",
                    "doc_weight": stats.get('weights', {}).get('document_weight', 0.6),
                    "graph_weight": stats.get('weights', {}).get('graph_weight', 0.4)
                }
            except Exception as e:
                logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                return {
                    "neo4j_nodes": 0,
                    "neo4j_relationships": 0,
                    "weaviate_entities": 0,
                    "weaviate_relations": 0,
                    "error": str(e)
                }
        return {
            "neo4j_nodes": 0,
            "neo4j_relationships": 0,
            "weaviate_entities": 0,
            "weaviate_relations": 0,
            "status": "æœªåˆå§‹åŒ–"
        }
    
    def search_knowledge(self, query, **kwargs):
        """æœç´¢çŸ¥è¯†"""
        if self.initialized and self.hybrid_service:
            try:
                import time
                start_time = time.time()
                
                # ä½¿ç”¨æ··åˆæ£€ç´¢æœåŠ¡è¿›è¡Œæœç´¢
                hybrid_result = self.hybrid_service.search_hybrid(query, top_k=10)
                
                retrieval_time = time.time() - start_time
                logger.info(f"æ··åˆæ£€ç´¢å®Œæˆï¼Œè€—æ—¶ {retrieval_time:.2f}s")
                
                # è½¬æ¢ç»“æœæ ¼å¼ä»¥å…¼å®¹ç°æœ‰çš„æ˜¾ç¤ºä»£ç 
                entities = []
                relations = []
                
                # å¤„ç†æ–‡æ¡£ç»“æœ
                for doc in hybrid_result.documents:
                    entity = {
                        'name': doc.get('metadata', {}).get('title', 'Document'),
                        'type': 'document',
                        'description': doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content'],
                        'similarity': f"{doc['score']:.3f}",
                        'distance': 1 - doc['score'],  # è½¬æ¢ä¸ºè·ç¦»
                        'source_text': doc['content'],
                        'metadata': doc.get('metadata', {}),
                        'source': 'weaviate'
                    }
                    entities.append(entity)
                
                # å¤„ç†å®ä½“ç»“æœ
                for entity_data in hybrid_result.entities:
                    # æ­£ç¡®æå–æè¿°å’Œæ ‡ç­¾ä¿¡æ¯
                    description = entity_data.get('description', '')
                    if not description:
                        # å¦‚æœæ²¡æœ‰æè¿°ï¼Œå°è¯•ä»propertiesä¸­è·å–
                        properties = entity_data.get('properties', {})
                        description = properties.get('description', 'N/A')
                    
                    entity = {
                        'name': entity_data.get('name', 'Unknown'),
                        'type': entity_data.get('type', 'entity'),
                        'description': description,
                        'labels': entity_data.get('labels', []),  # æ·»åŠ æ ‡ç­¾å­—æ®µ
                        'similarity': "N/A",  # å›¾è°±æ£€ç´¢æ²¡æœ‰ç›¸ä¼¼åº¦åˆ†æ•°
                        'distance': "N/A",
                        'source_text': '',
                        'metadata': entity_data.get('properties', {}),
                        'source': 'neo4j'
                    }
                    entities.append(entity)
                
                # å¤„ç†å…³ç³»ç»“æœ
                logger.info(f"å¤„ç†å…³ç³»ç»“æœï¼Œæ•°é‡: {len(hybrid_result.relationships)}")
                for i, rel_data in enumerate(hybrid_result.relationships):
                    logger.info(f"å…³ç³» {i}: {rel_data}")
                    # ä¿ç•™åŸå§‹æè¿°ï¼Œå¦‚æœæ²¡æœ‰æè¿°åˆ™ç”Ÿæˆé»˜è®¤æ ¼å¼
                    original_description = rel_data.get('description', '')
                    if not original_description or original_description.strip() == '':
                        description = f"{rel_data.get('source', 'N/A')} â†’ {rel_data.get('type', 'N/A')} â†’ {rel_data.get('target', 'N/A')}"
                    else:
                        description = original_description
                    
                    relation = {
                        'description': description,
                        'type': rel_data.get('type', 'N/A'),
                        'start_entity': rel_data.get('source', 'N/A'),
                        'end_entity': rel_data.get('target', 'N/A'),
                        'similarity': "N/A",
                        'distance': "N/A",
                        'metadata': rel_data.get('properties', {}),
                        'source': 'neo4j'
                    }
                    logger.info(f"æ ¼å¼åŒ–åçš„å…³ç³»: {relation}")
                    relations.append(relation)
                
                return {
                    "query": query,
                    "search_results": {
                        "vector_search": {
                            "entities": [e for e in entities if e['source'] == 'weaviate'],
                            "relations": []  # æ–‡æ¡£æ£€ç´¢ä¸è¿”å›å…³ç³»
                        },
                        "graph_search": {
                            "nodes": [e for e in entities if e['source'] == 'neo4j'],
                            "relationships": relations,
                            "total_nodes": len([e for e in entities if e['source'] == 'neo4j']),
                            "total_relationships": len(relations)
                        },
                        "hybrid_search": {
                            "search_stats": {
                                "vector_entities": len([e for e in entities if e['source'] == 'weaviate']),
                                "vector_relations": 0,
                                "graph_nodes": len([e for e in entities if e['source'] == 'neo4j']),
                                "graph_relationships": len(relations),
                                "combined_score": hybrid_result.combined_score
                            }
                        }
                    },
                    "retrieval_time": retrieval_time,
                    "hybrid_metadata": hybrid_result.metadata
                }
                
            except Exception as e:
                logger.error(f"çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
                return {
                    "error": str(e),
                    "query": query,
                    "search_results": {}
                }
        else:
            logger.error("æ··åˆRAGç³»ç»Ÿæœªåˆå§‹åŒ–")
            return {
                "error": "æ··åˆRAGç³»ç»Ÿæœªåˆå§‹åŒ–",
                "query": query,
                "search_results": {}
            }
    
    def generate_answer(self, query, search_results=None):
        """ç”Ÿæˆç­”æ¡ˆ"""
        if self.initialized and self.rag_pipeline:
            try:
                # ä½¿ç”¨RAGç®¡é“ç”Ÿæˆç­”æ¡ˆ
                rag_response = self.rag_pipeline.generate_answer(
                    question=query,
                    top_k=10,
                    include_sources=True
                )
                
                # æ ¼å¼åŒ–ç­”æ¡ˆ
                answer_parts = [rag_response.answer]
                
                if rag_response.sources:
                    answer_parts.append("\n\n**å‚è€ƒæ¥æº:**")
                    for i, source in enumerate(rag_response.sources[:5], 1):
                        if source['type'] == 'document':
                            answer_parts.append(f"{i}. æ–‡æ¡£: {source['content']}")
                        elif source['type'] == 'entity':
                            answer_parts.append(f"{i}. å®ä½“: {source['name']} ({source['entity_type']})")
                        elif source['type'] == 'relationship':
                            answer_parts.append(f"{i}. å…³ç³»: {source['source_entity']} â†’ {source['relation_type']} â†’ {source['target_entity']}")
                
                return "\n".join(answer_parts)
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
        else:
            return "æ··åˆRAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"


class SimpleRAGSystem:
    """ç®€åŒ–çš„RAGç³»ç»Ÿï¼Œä»…ä½¿ç”¨Neo4jçŸ¥è¯†å›¾è°±"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®€åŒ–RAGç³»ç»Ÿ"""
        self.kg_builder = None
        self.neo4j_graph = None
        self.vector_processor = None
        self.initialized = False
        
        try:
            if SIMPLE_RAG_AVAILABLE:
                # è·å–é…ç½®
                config = get_config()
                
                # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ„å»ºå™¨
                self.kg_builder = KnowledgeGraphBuilder()
                # åˆå§‹åŒ–Neo4jè¿æ¥
                self.neo4j_graph = Graph(config.neo4j.uri, auth=(config.neo4j.username, config.neo4j.password))
                
                # å°è¯•åˆå§‹åŒ–å‘é‡å¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
                try:
                    from src.knowledge.vector_storage import WeaviateVectorStore
                    embedding_client = OllamaEmbeddingClient()
                    vector_store = WeaviateVectorStore()
                    # æš‚æ—¶ç¦ç”¨å‘é‡å¤„ç†å™¨ï¼Œå› ä¸ºVectorKnowledgeProcessorç±»ä¸å­˜åœ¨
                    self.vector_processor = None
                    logger.info("å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸï¼Œä½†å‘é‡å¤„ç†å™¨æš‚æ—¶ç¦ç”¨")
                except Exception as ve:
                    logger.warning(f"å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨å›¾è°±æ£€ç´¢: {ve}")
                    self.vector_processor = None
                
                self.initialized = True
                logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("ç®€åŒ–RAGç³»ç»Ÿä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.initialized = False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if self.initialized and self.neo4j_graph:
            try:
                # æŸ¥è¯¢Neo4jç»Ÿè®¡ä¿¡æ¯
                node_count = self.neo4j_graph.run("MATCH (n) RETURN count(n) as count").data()[0]['count']
                rel_count = self.neo4j_graph.run("MATCH ()-[r]->() RETURN count(r) as count").data()[0]['count']
                
                return {
                    "neo4j_nodes": node_count,
                    "neo4j_relationships": rel_count,
                    "weaviate_entities": 0,  # ç®€åŒ–ç‰ˆæœ¬ä¸ä½¿ç”¨Weaviate
                    "weaviate_relations": 0,
                    "status": "ç®€åŒ–ç‰ˆæœ¬"
                }
            except Exception as e:
                logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
                return {
                    "neo4j_nodes": 0,
                    "neo4j_relationships": 0,
                    "weaviate_entities": 0,
                    "weaviate_relations": 0,
                    "error": str(e)
                }
        return {
            "neo4j_nodes": 0,
            "neo4j_relationships": 0,
            "weaviate_entities": 0,
            "weaviate_relations": 0,
            "status": "æœªåˆå§‹åŒ–"
        }
    
    def search_knowledge(self, query, **kwargs):
        """æœç´¢çŸ¥è¯†"""
        if self.initialized and self.neo4j_graph:
            try:
                import time
                start_time = time.time()
                
                # ä½¿ç”¨Neo4jè¿›è¡Œç®€å•çš„å…³é”®è¯æœç´¢ï¼Œæ”¯æŒä¸­è‹±æ–‡
                search_query = f"""
                MATCH (n)
                WHERE toLower(n.name) CONTAINS toLower('{query}') 
                   OR toLower(toString(n.description)) CONTAINS toLower('{query}')
                   OR toLower(n.name) CONTAINS toLower('parkinson') 
                   OR toLower(toString(n.description)) CONTAINS toLower('parkinson')
                OPTIONAL MATCH (n)-[r]-(m)
                RETURN n, r, m
                LIMIT 20
                """
                
                logger.info(f"æ‰§è¡ŒNeo4jæŸ¥è¯¢: {search_query}")
                results = self.neo4j_graph.run(search_query).data()
                logger.info(f"Neo4jæŸ¥è¯¢è¿”å› {len(results)} æ¡ç»“æœ")
                
                # æ ¼å¼åŒ–ç»“æœ
                nodes = []
                relationships = []
                seen_nodes = set()
                
                for record in results:
                    if record['n']:
                        node = record['n']
                        node_id = id(node)
                        if node_id not in seen_nodes:
                            node_data = dict(node)
                            node_data['labels'] = list(node.labels)
                            nodes.append(node_data)
                            seen_nodes.add(node_id)
                    
                    if record['r'] and record['m']:
                        rel_data = {
                            'type': type(record['r']).__name__,
                            'properties': dict(record['r']),
                            'start_node': dict(record['n']),
                            'end_node': dict(record['m'])
                        }
                        relationships.append(rel_data)
                
                retrieval_time = time.time() - start_time
                logger.info(f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(relationships)} ä¸ªå…³ç³»ï¼Œè€—æ—¶ {retrieval_time:.2f}s")
                
                # å°è¯•å‘é‡æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                vector_entities = []
                vector_relations = []
                hybrid_knowledge = ""
                
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡å­˜å‚¨å¯ç”¨
                    if hasattr(self, 'vector_processor') and self.vector_processor:
                        # ä½¿ç”¨æ··åˆå‘é‡æ£€ç´¢
                        hybrid_results = self.vector_processor.search_knowledge_hybrid(query, limit=5)
                        
                        # æå–å‘é‡æ£€ç´¢ç»“æœ
                        vector_entities = hybrid_results.get('cosine_results', [])
                        vector_relations = hybrid_results.get('euclidean_results', [])
                        
                        # è·å–æ ¼å¼åŒ–çš„çŸ¥è¯†å†…å®¹ç”¨äºæç¤ºè¯
                        hybrid_knowledge = self.vector_processor.get_knowledge_for_prompt(query, limit=5)
                        
                        # è·å–æ£€ç´¢ç»Ÿè®¡
                        retrieval_stats = hybrid_results.get('retrieval_stats', {})
                        logger.info(f"æ··åˆå‘é‡æ£€ç´¢å®Œæˆ: æ€»è®¡ {retrieval_stats.get('total_found', 0)} ä¸ªç‰‡æ®µï¼Œ"
                                  f"ä½™å¼¦ç›¸ä¼¼åº¦ {retrieval_stats.get('cosine_count', 0)} ä¸ªï¼Œ"
                                  f"æ¬§æ°è·ç¦» {retrieval_stats.get('euclidean_count', 0)} ä¸ª")
                    else:
                        logger.info("å‘é‡å­˜å‚¨ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡æ£€ç´¢")
                except Exception as ve:
                    logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {ve}")
                
                return {
                    "query": query,
                    "search_results": {
                        "graph_search": {
                            "nodes": nodes,
                            "relationships": relationships,
                            "total_nodes": len(nodes),
                            "total_relationships": len(relationships)
                        },
                        "vector_search": {
                            "entities": vector_entities,
                            "relations": vector_relations,
                            "hybrid_knowledge": hybrid_knowledge
                        },
                        "hybrid_search": {
                            "search_stats": {
                                "graph_nodes": len(nodes),
                                "graph_relationships": len(relationships),
                                "vector_entities": len(vector_entities),
                                "vector_relations": len(vector_relations),
                                "has_hybrid_knowledge": bool(hybrid_knowledge)
                            }
                        }
                    },
                    "retrieval_time": retrieval_time
                }
                
            except Exception as e:
                logger.error(f"çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
                return {
                    "error": str(e),
                    "query": query,
                    "search_results": {}
                }
        else:
            logger.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–æˆ–Neo4jè¿æ¥å¤±è´¥")
            return {
                "error": "RAGç³»ç»Ÿæœªåˆå§‹åŒ–",
                "query": query,
                "search_results": {}
            }
    
    def generate_answer(self, query, search_results=None):
        """ç”Ÿæˆç­”æ¡ˆ"""
        if self.initialized and self.kg_builder:
            try:
                if search_results and search_results.get("search_results"):
                    # åŸºäºæœç´¢ç»“æœæ„å»ºä¸Šä¸‹æ–‡
                    context_parts = []
                    graph_search = search_results["search_results"].get("graph_search", {})
                    vector_search = search_results["search_results"].get("vector_search", {})
                    
                    # ä¼˜å…ˆä½¿ç”¨æ··åˆå‘é‡æ£€ç´¢çš„çŸ¥è¯†å†…å®¹
                    hybrid_knowledge = vector_search.get("hybrid_knowledge", "")
                    if hybrid_knowledge and hybrid_knowledge != "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å†…å®¹ã€‚":
                        context_parts.append("ğŸ“š å‘é‡æ£€ç´¢çŸ¥è¯†:")
                        context_parts.append(hybrid_knowledge)
                    
                    # æ·»åŠ å›¾è°±æœç´¢ç»“æœ
                    if graph_search.get("nodes"):
                        context_parts.append("\nğŸ” å›¾è°±å®ä½“:")
                        for node in graph_search["nodes"][:3]:  # å‡å°‘æ˜¾ç¤ºæ•°é‡ï¼Œé¿å…è¿‡é•¿
                            name = node.get("name", "æœªçŸ¥")
                            labels = ", ".join(node.get("labels", []))
                            context_parts.append(f"- {name} ({labels})")
                            if node.get("description"):
                                desc = node['description'][:100] + "..." if len(node['description']) > 100 else node['description']
                                context_parts.append(f"  æè¿°: {desc}")
                    
                    if graph_search.get("relationships"):
                        context_parts.append("\nğŸ”— å›¾è°±å…³ç³»:")
                        for rel in graph_search["relationships"][:2]:  # å‡å°‘æ˜¾ç¤ºæ•°é‡
                            start_name = rel.get("start_node", {}).get("name", "æœªçŸ¥")
                            end_name = rel.get("end_node", {}).get("name", "æœªçŸ¥")
                            rel_type = rel.get("type", "ç›¸å…³")
                            context_parts.append(f"- {start_name} â†’ {rel_type} â†’ {end_name}")
                    
                    context = "\n".join(context_parts)
                    
                    # æ„å»ºå¢å¼ºçš„æç¤ºè¯
                    if hybrid_knowledge and hybrid_knowledge != "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å†…å®¹ã€‚":
                        prompt = f"""åŸºäºä»¥ä¸‹åŒ»ç–—çŸ¥è¯†å›ç­”é—®é¢˜ï¼š

é—®é¢˜: {query}

{context}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†å†…å®¹ï¼Œæä¾›å‡†ç¡®ã€ä¸“ä¸šçš„åŒ»ç–—å›ç­”ã€‚é‡ç‚¹å…³æ³¨å‘é‡æ£€ç´¢çš„çŸ¥è¯†å†…å®¹ï¼Œç»“åˆå›¾è°±ä¿¡æ¯è¿›è¡Œè¡¥å……ã€‚å›ç­”è¦æ±‚ï¼š
1. å‡†ç¡®æ€§ï¼šåŸºäºæä¾›çš„çŸ¥è¯†å†…å®¹å›ç­”
2. å®Œæ•´æ€§ï¼šå°½å¯èƒ½å…¨é¢åœ°å›ç­”é—®é¢˜
3. ä¸“ä¸šæ€§ï¼šä½¿ç”¨åŒ»ç–—ä¸“ä¸šæœ¯è¯­ï¼Œä½†è¦é€šä¿—æ˜“æ‡‚
4. å®‰å…¨æ€§ï¼šå¦‚æ¶‰åŠè¯Šæ–­æ²»ç–—ï¼Œè¯·æé†’å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ"""
                    else:
                        prompt = f"""åŸºäºä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

é—®é¢˜: {query}

çŸ¥è¯†æ¥æº:
{context}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼Œæä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜éœ€è¦æ›´å¤šå“ªæ–¹é¢çš„ä¿¡æ¯ã€‚"""
                    
                    # ä½¿ç”¨Ollamaç”Ÿæˆå›ç­”
                    response = self.kg_builder.recognizer.ollama.generate(prompt)
                    return response
                else:
                    # ç›´æ¥å›ç­”
                    prompt = f"è¯·å›ç­”ä»¥ä¸‹åŒ»ç–—ç›¸å…³é—®é¢˜ï¼š{query}\n\nè¯·æä¾›ä¸“ä¸šã€å‡†ç¡®çš„å›ç­”ï¼Œå¦‚æ¶‰åŠè¯Šæ–­æ²»ç–—å»ºè®®ï¼Œè¯·æé†’å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚"
                    response = self.kg_builder.recognizer.ollama.generate(prompt)
                    return response
                    
            except Exception as e:
                logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
                return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
        else:
            return "RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆ"


class RealRAGSystem:
    """çœŸå®çš„RAGç³»ç»ŸåŒ…è£…å™¨"""
    
    def __init__(self):
        self.rag_system = None
        self.rag_chain = None
        self.retriever = None
        self.prompt_template = None
        self.initialized = False
    
    def initialize(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        try:
            if not REAL_RAG_AVAILABLE:
                raise ImportError("çœŸå®RAGç³»ç»Ÿç»„ä»¶ä¸å¯ç”¨")
            
            # åˆå§‹åŒ–ModularRAGSystem
            self.rag_system = ModularRAGSystem()
            
            # åˆ›å»ºRAGé“¾
            self.rag_chain, self.retriever, self.prompt_template = create_rag_chain(self.rag_system)
            
            self.initialized = True
            return True
            
        except Exception as e:
            st.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def get_stats(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if not self.initialized or not self.rag_system:
            return {}
        
        try:
            return self.rag_system.get_stats()
        except Exception as e:
            st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def search_knowledge(self, query: str) -> Dict[str, Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        if not self.initialized:
            return {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}},
                'error': 'ç³»ç»Ÿæœªåˆå§‹åŒ–'
            }
        
        try:
            # ä½¿ç”¨ModularRAGSystemçš„æœç´¢åŠŸèƒ½
            start_time = time.time()
            search_result = self.rag_system.search(query)
            retrieval_time = time.time() - start_time
            
            # ä»æœç´¢ç»“æœä¸­æå–æ£€ç´¢è¯¦æƒ…
            details = search_result.get('retrieval_details', {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}}
            })
            
            # æ·»åŠ æ£€ç´¢æ—¶é—´
            if 'hybrid_results' not in details:
                details['hybrid_results'] = {}
            if 'search_stats' not in details['hybrid_results']:
                details['hybrid_results']['search_stats'] = {}
            details['hybrid_results']['search_stats']['total_time'] = retrieval_time
            
            return details
            
        except Exception as e:
            st.error(f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}")
            return {
                'vector_results': {'entities': [], 'relations': []},
                'graph_results': {'nodes': [], 'relationships': [], 'total_nodes': 0, 'total_relationships': 0},
                'hybrid_results': {'search_stats': {}},
                'error': str(e)
            }
    
    def generate_answer(self, query: str) -> str:
        """ç”Ÿæˆå›ç­”"""
        if not self.initialized:
            return "RAGç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚"
        
        try:
            # ä½¿ç”¨ModularRAGSystemçš„æœç´¢åŠŸèƒ½è·å–å®Œæ•´ç»“æœ
            search_result = self.rag_system.search(query)
            answer = search_result.get('answer', 'æ— æ³•ç”Ÿæˆå›ç­”')
            return answer
            
        except Exception as e:
            st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {str(e)}")
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"
    
    def close(self):
        """å…³é—­RAGç³»ç»Ÿ"""
        if self.rag_system:
            try:
                self.rag_system.close()
            except:
                pass

class MockRAGRetriever:
    """æ¨¡æ‹ŸRAGæ£€ç´¢å™¨ï¼Œç”¨äºå±•ç¤ºæ£€ç´¢è¿‡ç¨‹"""
    
    def __init__(self):
        # æ¨¡æ‹ŸçŸ¥è¯†åº“
        self.knowledge_base = {
            "å¸•é‡‘æ£®ç—…": {
                "symptoms": ["é™æ­¢æ€§éœ‡é¢¤", "è¿åŠ¨è¿Ÿç¼“", "è‚Œè‚‰åƒµç›´", "å§¿åŠ¿ä¸ç¨³"],
                "causes": ["å¤šå·´èƒºç¥ç»å…ƒé€€åŒ–", "é—ä¼ å› ç´ ", "ç¯å¢ƒå› ç´ "],
                "treatments": ["è¯ç‰©æ²»ç–—", "æ·±éƒ¨è„‘åˆºæ¿€", "åº·å¤è®­ç»ƒ"],
                "source": "åŒ»å­¦æ•™ç§‘ä¹¦ç¬¬12ç‰ˆ"
            },
            "é«˜è¡€å‹": {
                "symptoms": ["å¤´ç—›", "å¤´æ™•", "å¿ƒæ‚¸", "è§†åŠ›æ¨¡ç³Š"],
                "prevention": ["ä½ç›é¥®é£Ÿ", "è§„å¾‹è¿åŠ¨", "æ§åˆ¶ä½“é‡", "æˆ’çƒŸé™é…’"],
                "treatments": ["ACEæŠ‘åˆ¶å‰‚", "åˆ©å°¿å‰‚", "é’™é€šé“é˜»æ»å‰‚"],
                "source": "å¿ƒè¡€ç®¡ç–¾ç—…æŒ‡å—2023"
            },
            "ç³–å°¿ç—…": {
                "types": ["1å‹ç³–å°¿ç—…", "2å‹ç³–å°¿ç—…", "å¦Šå¨ ç³–å°¿ç—…"],
                "diet": ["æ§åˆ¶ç¢³æ°´åŒ–åˆç‰©", "å¢åŠ çº¤ç»´æ‘„å…¥", "å®šæ—¶å®šé‡", "é¿å…é«˜ç³–é£Ÿç‰©"],
                "complications": ["ç³–å°¿ç—…è‚¾ç—…", "ç³–å°¿ç—…è§†ç½‘è†œç—…å˜", "ç³–å°¿ç—…è¶³"],
                "source": "ç³–å°¿ç—…è¯Šç–—æŒ‡å—2023"
            }
        }
    
    def search_knowledge(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹ŸçŸ¥è¯†æ£€ç´¢è¿‡ç¨‹"""
        # æ¨¡æ‹Ÿæ£€ç´¢å»¶è¿Ÿ
        time.sleep(0.5)
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        results = {
            "query": query,
            "vector_results": [],
            "graph_results": [],
            "hybrid_results": [],
            "total_time": round(random.uniform(0.3, 1.2), 2)
        }
        
        # æ¨¡æ‹Ÿå‘é‡æ£€ç´¢
        for disease, info in self.knowledge_base.items():
            if disease in query:
                similarity = round(random.uniform(0.7, 0.95), 3)
                results["vector_results"].append({
                    "entity": disease,
                    "similarity": similarity,
                    "content": str(info),
                    "source": info.get("source", "æœªçŸ¥æ¥æº")
                })
        
        # æ¨¡æ‹Ÿå›¾è°±æ£€ç´¢
        if results["vector_results"]:
            main_entity = results["vector_results"][0]["entity"]
            results["graph_results"] = [
                {"relation": "ç—‡çŠ¶", "entities": self.knowledge_base[main_entity].get("symptoms", [])},
                {"relation": "æ²»ç–—", "entities": self.knowledge_base[main_entity].get("treatments", [])},
            ]
        
        # æ¨¡æ‹Ÿæ··åˆæ£€ç´¢
        results["hybrid_results"] = results["vector_results"][:3]  # å–å‰3ä¸ªç»“æœ
        
        return results
    
    def generate_answer(self, query: str) -> str:
        """æ¨¡æ‹Ÿç”Ÿæˆå›ç­”"""
        # ç®€å•çš„æ¨¡æ‹Ÿå›ç­”
        for disease, info in self.knowledge_base.items():
            if disease in query:
                answer_parts = [f"å…³äº{disease}çš„ä¿¡æ¯ï¼š"]
                
                if "symptoms" in info:
                    answer_parts.append(f"ä¸»è¦ç—‡çŠ¶åŒ…æ‹¬ï¼š{', '.join(info['symptoms'])}")
                
                if "treatments" in info:
                    answer_parts.append(f"æ²»ç–—æ–¹æ³•åŒ…æ‹¬ï¼š{', '.join(info['treatments'])}")
                
                if "prevention" in info:
                    answer_parts.append(f"é¢„é˜²æªæ–½åŒ…æ‹¬ï¼š{', '.join(info['prevention'])}")
                
                answer_parts.append("\næ³¨æ„ï¼šæœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œå¦‚æœ‰ç–‘é—®è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚")
                
                return "\n\n".join(answer_parts)
        
        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³çš„åŒ»ç–—ä¿¡æ¯ã€‚å»ºè®®æ‚¨å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿè·å–å‡†ç¡®çš„åŒ»ç–—å»ºè®®ã€‚"

def display_retrieval_process(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºæ£€ç´¢è¿‡ç¨‹è¯¦æƒ… - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ” æ£€ç´¢è¿‡ç¨‹è¯¦æƒ…", expanded=False):
        # æ£€ç´¢ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        hybrid_search = search_results.get('hybrid_search', {})
        search_stats = hybrid_search.get('search_stats', {})
        
        with col1:
            vector_count = len(vector_search.get('entities', [])) + len(vector_search.get('relations', []))
            st.metric("å‘é‡æ£€ç´¢", vector_count)
        
        with col2:
            graph_count = graph_search.get('total_nodes', 0)
            st.metric("å›¾è°±æ£€ç´¢", graph_count)
        
        with col3:
            hybrid_count = search_stats.get('graph_nodes', 0) + search_stats.get('vector_entities', 0)
            st.metric("æ··åˆæ£€ç´¢", hybrid_count)
        
        with col4:
            retrieval_time = retrieval_results.get('retrieval_time', 0)
            if isinstance(retrieval_time, (int, float)):
                st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_time:.2f}s")
            else:
                st.metric("æ£€ç´¢è€—æ—¶", "0.00s")

def display_detailed_results(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºè¯¦ç»†æ£€ç´¢ç»“æœ - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ“Š è¯¦ç»†æ£€ç´¢ç»“æœ", expanded=False):
        # åˆ›å»ºä¸‰ä¸ªæ ‡ç­¾é¡µ
        tab1, tab2, tab3 = st.tabs(["ğŸ” å‘é‡æ£€ç´¢", "ğŸ•¸ï¸ å›¾è°±æ£€ç´¢", "ğŸ”„ æ··åˆæ£€ç´¢"])
        
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        hybrid_search = search_results.get('hybrid_search', {})
        
        with tab1:
            entities = vector_search.get('entities', [])
            relations = vector_search.get('relations', [])
            
            if entities:
                st.markdown("### ğŸ¯ **å®ä½“ç»“æœ**")
                st.write("")
                
                for i, entity in enumerate(entities, 1):  # æ˜¾ç¤ºæ‰€æœ‰å®ä½“ï¼Œä¸é™åˆ¶ä¸º5ä¸ª
                    similarity = entity.get('similarity', 'N/A')
                    name = entity.get('name', 'N/A')
                    description = entity.get('description', 'N/A')
                    distance = entity.get('distance', 'N/A')
                    metadata = entity.get('metadata', {})
                    
                    # åˆ›å»ºç¾è§‚çš„å®ä½“å¡ç‰‡
                    with st.container():
                        st.markdown(f"#### ğŸ¯ **å®ä½“ {i}: {name}**")
                        
                        # æè¿°æ˜¾ç¤º
                        if description and description != 'N/A':
                            st.markdown(f"**ğŸ“ æè¿°**: {description}")
                        else:
                            st.markdown("**ğŸ“ æè¿°**: *æš‚æ— æè¿°*")
                        
                        # æ˜¾ç¤ºè¯¦ç»†çš„è·ç¦»ä¿¡æ¯
                        st.markdown("**ğŸ“Š ç›¸ä¼¼åº¦æŒ‡æ ‡**:")
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            if similarity != 'N/A':
                                st.metric("ç»¼åˆç›¸ä¼¼åº¦", f"{similarity}")
                            else:
                                st.metric("ç»¼åˆç›¸ä¼¼åº¦", "N/A")
                        with col2:
                            # ä»metadataä¸­è·å–ä½™å¼¦ç›¸ä¼¼åº¦
                            cosine_similarity = metadata.get('cosine_similarity', 'N/A')
                            if cosine_similarity == 'N/A' and distance != 'N/A':
                                # å¦‚æœæ²¡æœ‰ç›´æ¥çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå°è¯•ä»distanceè®¡ç®—
                                try:
                                    cosine_similarity = f"{1 - float(distance):.3f}"
                                except:
                                    cosine_similarity = 'N/A'
                            elif isinstance(cosine_similarity, (int, float)):
                                cosine_similarity = f"{cosine_similarity:.3f}"
                            st.metric("ä½™å¼¦ç›¸ä¼¼åº¦", cosine_similarity)
                        with col3:
                            # ä»metadataä¸­è·å–æ¬§æ°è·ç¦»
                            euclidean_distance = metadata.get('euclidean_distance', 'N/A')
                            if isinstance(euclidean_distance, (int, float)):
                                euclidean_distance = f"{euclidean_distance:.3f}"
                                st.metric("æ¬§æ°è·ç¦»", euclidean_distance)
                            else:
                                st.metric("æ¬§æ°è·ç¦»", "N/A")
                        
                        # æ˜¾ç¤ºå…¶ä»–metadataä¿¡æ¯
                        other_metadata = {k: v for k, v in metadata.items() 
                                        if k not in ['cosine_similarity', 'euclidean_distance']}
                        if other_metadata:
                            st.markdown("**ğŸ”§ å…¶ä»–è¯¦ç»†ä¿¡æ¯**:")
                            for key, value in other_metadata.items():
                                st.write(f"â€¢ **{key}**: {value}")
                        
                        st.markdown("---")
            
            if relations:
                st.markdown("### ğŸ”— **å…³ç³»ç»“æœ**")
                st.write("")
                
                for i, relation in enumerate(relations, 1):  # æ˜¾ç¤ºæ‰€æœ‰å…³ç³»ï¼Œä¸é™åˆ¶ä¸º5ä¸ª
                    description = relation.get('description', 'N/A')
                    similarity = relation.get('similarity', 'N/A')
                    distance = relation.get('distance', 'N/A')
                    metadata = relation.get('metadata', {})
                    
                    # åˆ›å»ºç¾è§‚çš„å…³ç³»å¡ç‰‡
                    with st.container():
                        st.markdown(f"#### ğŸ”— **å…³ç³» {i}**")
                        
                        # å…³ç³»æè¿°
                        if description and description != 'N/A':
                            st.markdown(f"**ğŸ“ æè¿°**: {description}")
                        else:
                            st.markdown("**ğŸ“ æè¿°**: *æš‚æ— æè¿°*")
                        
                        # æ˜¾ç¤ºè¯¦ç»†çš„è·ç¦»ä¿¡æ¯
                        if similarity != 'N/A' or distance != 'N/A' or metadata:
                            st.markdown("**ğŸ“Š ç›¸ä¼¼åº¦æŒ‡æ ‡**:")
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                if similarity != 'N/A':
                                    st.metric("ç»¼åˆç›¸ä¼¼åº¦", f"{similarity}")
                                else:
                                    st.metric("ç»¼åˆç›¸ä¼¼åº¦", "N/A")
                            with col2:
                                # ä»metadataä¸­è·å–ä½™å¼¦ç›¸ä¼¼åº¦
                                cosine_similarity = metadata.get('cosine_similarity', 'N/A')
                                if cosine_similarity == 'N/A' and distance != 'N/A':
                                    try:
                                        cosine_similarity = f"{1 - float(distance):.3f}"
                                    except:
                                        cosine_similarity = 'N/A'
                                elif isinstance(cosine_similarity, (int, float)):
                                    cosine_similarity = f"{cosine_similarity:.3f}"
                                st.metric("ä½™å¼¦ç›¸ä¼¼åº¦", cosine_similarity)
                            with col3:
                                # ä»metadataä¸­è·å–æ¬§æ°è·ç¦»
                                euclidean_distance = metadata.get('euclidean_distance', 'N/A')
                                if isinstance(euclidean_distance, (int, float)):
                                    euclidean_distance = f"{euclidean_distance:.3f}"
                                    st.metric("æ¬§æ°è·ç¦»", euclidean_distance)
                                else:
                                    st.metric("æ¬§æ°è·ç¦»", "N/A")
                        
                        st.markdown("---")
            
            if not entities and not relations:
                st.info("ğŸ” æœªæ‰¾åˆ°ç›¸å…³å‘é‡ç»“æœ")
        
        with tab2:
            # è·å–å›¾è°±æ£€ç´¢ç»“æœ
            nodes = graph_search.get('nodes', [])
            relationships = graph_search.get('relationships', [])
            
            # æ˜¾ç¤ºèŠ‚ç‚¹ç»“æœ
            if nodes:
                st.markdown("### ğŸ” èŠ‚ç‚¹ç»“æœ")
                st.write("")
                
                for i, node in enumerate(nodes, 1):
                    # è·å–èŠ‚ç‚¹ä¿¡æ¯
                    name = node.get('name', 'N/A')
                    description = node.get('description', 'N/A')
                    labels = node.get('labels', [])
                    node_type = node.get('type', 'N/A')
                    distance = node.get('distance', 'N/A')
                    metadata = node.get('metadata', {})
                    similarity = node.get('similarity', 'N/A')
                    source_text = node.get('source_text', '')
                    source = node.get('source', 'neo4j')
                    
                    # æ˜¾ç¤ºèŠ‚ç‚¹ä¿¡æ¯
                    st.markdown(f"ğŸ“ **èŠ‚ç‚¹ {i}: {name}**")
                    
                    # æ ‡ç­¾
                    if labels and len(labels) > 0:
                        label_str = ', '.join(labels)
                        st.write(f"ğŸ·ï¸ æ ‡ç­¾: {label_str}")
                    else:
                        st.write("ğŸ·ï¸ æ ‡ç­¾: æ— æ ‡ç­¾")
                    
                    st.write("")
                    
                    # æè¿°
                    if description and description != 'N/A':
                        st.write(f"ğŸ“ æè¿°: {description}")
                    else:
                        st.write("ğŸ“ æè¿°: æš‚æ— æè¿°")
                    
                    st.write("")
                    
                    # å…¶ä»–å±æ€§
                    st.write("ğŸ”§ å…¶ä»–å±æ€§:")
                    st.write("")
                    st.write(f"type: {node_type}")
                    st.write("")
                    st.write(f"distance: {distance}")
                    st.write("")
                    st.write(f"metadata: {metadata}")
                    st.write("")
                    st.write(f"similarity: {similarity}")
                    st.write("")
                    st.write(f"source_text: {source_text}")
                    st.write("")
                    st.write(f"æ•°æ®æº: {source}")
                    st.write("")
                    
                    st.markdown("---")
            
            # æ˜¾ç¤ºå…³ç³»ç»“æœ
            if relationships:
                st.markdown("### ğŸ”— å…³ç³»ç»“æœ")
                st.write("")
                
                for i, rel in enumerate(relationships, 1):
                    # è·å–å…³ç³»ä¿¡æ¯
                    rel_type = rel.get('type', 'N/A')
                    start_entity = rel.get('start_entity', 'N/A')
                    end_entity = rel.get('end_entity', 'N/A')
                    description = rel.get('description', 'N/A')
                    
                    # åˆ›å»ºç¾è§‚çš„å…³ç³»å¡ç‰‡
                    with st.container():
                        # å…³ç³»æ ‡é¢˜å’Œç±»å‹
                        st.markdown(f"#### ğŸ”— **å…³ç³» {i}: `{rel_type}`**")
                        
                        # å…³ç³»è·¯å¾„å¯è§†åŒ–
                        st.markdown(f"**ğŸ“ å…³ç³»è·¯å¾„**: `{start_node}` â¡ï¸ **{rel_type}** â¡ï¸ `{end_node}`")
                        
                        # è¯¦ç»†ä¿¡æ¯
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown(f"**ğŸ¯ èµ·å§‹èŠ‚ç‚¹**: `{start_node}`")
                        with col2:
                            st.markdown(f"**ğŸ¯ ç»“æŸèŠ‚ç‚¹**: `{end_node}`")
                        
                        # å…³ç³»æè¿°
                        if description and description != 'N/A':
                            st.markdown(f"**ğŸ“ æè¿°**: {description}")
                        else:
                            st.markdown("**ğŸ“ æè¿°**: *æš‚æ— æè¿°*")
                        
                        # å…¶ä»–å±æ€§
                        other_props = {k: v for k, v in rel.items() 
                                     if k not in ['type', 'start_entity', 'end_entity', 'description']}
                        if other_props:
                            st.markdown("**ğŸ”§ å…¶ä»–å±æ€§**:")
                            cols = st.columns(3)
                            prop_items = list(other_props.items())
                            for idx, (key, value) in enumerate(prop_items):
                                col_idx = idx % 3
                                with cols[col_idx]:
                                    if key in ['similarity', 'distance']:
                                        if value != 'N/A':
                                            st.write(f"**{key}**: `{value}`")
                                        else:
                                            st.write(f"**{key}**: *N/A*")
                                    elif key == 'source':
                                        st.write(f"**æ•°æ®æº**: `{value}`")
                                    elif key == 'metadata' and value:
                                        st.write(f"**å…ƒæ•°æ®**: {value}")
                                    else:
                                        st.write(f"**{key}**: {value}")
                        
                        st.markdown("---")
            
            # å¦‚æœæ²¡æœ‰ç»“æœ
            if not nodes and not relationships:
                st.info("ğŸ” æœªæ‰¾åˆ°ç›¸å…³å›¾è°±ç»“æœ")
        
        with tab3:
            search_stats = hybrid_search.get('search_stats', {})
            
            if search_stats:
                st.write("**æ£€ç´¢ç»Ÿè®¡:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    graph_nodes = search_stats.get('graph_nodes', 0)
                    graph_relationships = search_stats.get('graph_relationships', 0)
                    vector_entities = search_stats.get('vector_entities', 0)
                    vector_relations = search_stats.get('vector_relations', 0)
                    
                    st.metric("å›¾è°±èŠ‚ç‚¹", graph_nodes)
                    st.metric("å›¾è°±å…³ç³»", graph_relationships)
                    
                with col2:
                    st.metric("å‘é‡å®ä½“", vector_entities)
                    st.metric("å‘é‡å…³ç³»", vector_relations)
                    
                    retrieval_time = retrieval_results.get('retrieval_time', 0)
                    if isinstance(retrieval_time, (int, float)):
                        st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_time:.3f}s")
                    else:
                        st.metric("æ£€ç´¢è€—æ—¶", "N/A")
                
                # æ·»åŠ è·ç¦»åº¦é‡è¯¦ç»†ä¿¡æ¯
                st.write("---")
                st.write("**è·ç¦»åº¦é‡è¯¦æƒ…:**")
                
                # æ˜¾ç¤ºæ··åˆæ£€ç´¢çš„æƒé‡é…ç½®
                st.info("ğŸ”§ **æ··åˆæ£€ç´¢é…ç½®**: ä½™å¼¦ç›¸ä¼¼åº¦æƒé‡ 70% + æ¬§æ°è·ç¦»æƒé‡ 30%")
                
                # åˆ†æå®ä½“ç»“æœçš„è·ç¦»åˆ†å¸ƒ
                entities = vector_search.get('entities', [])
                if entities:
                    st.write("**å®ä½“è·ç¦»åˆ†å¸ƒ:**")
                    
                    cosine_values = []
                    euclidean_values = []
                    
                    for entity in entities:
                        metadata = entity.get('metadata', {})
                        cosine_sim = metadata.get('cosine_similarity')
                        euclidean_dist = metadata.get('euclidean_distance')
                        
                        if isinstance(cosine_sim, (int, float)):
                            cosine_values.append(cosine_sim)
                        if isinstance(euclidean_dist, (int, float)):
                            euclidean_values.append(euclidean_dist)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if cosine_values:
                            avg_cosine = sum(cosine_values) / len(cosine_values)
                            max_cosine = max(cosine_values)
                            min_cosine = min(cosine_values)
                            st.write("**ä½™å¼¦ç›¸ä¼¼åº¦ç»Ÿè®¡:**")
                            st.write(f"- å¹³å‡å€¼: {avg_cosine:.3f}")
                            st.write(f"- æœ€å¤§å€¼: {max_cosine:.3f}")
                            st.write(f"- æœ€å°å€¼: {min_cosine:.3f}")
                        else:
                            st.write("**ä½™å¼¦ç›¸ä¼¼åº¦**: æ— æ•°æ®")
                    
                    with col2:
                        if euclidean_values:
                            avg_euclidean = sum(euclidean_values) / len(euclidean_values)
                            max_euclidean = max(euclidean_values)
                            min_euclidean = min(euclidean_values)
                            st.write("**æ¬§æ°è·ç¦»ç»Ÿè®¡:**")
                            st.write(f"- å¹³å‡å€¼: {avg_euclidean:.3f}")
                            st.write(f"- æœ€å¤§å€¼: {max_euclidean:.3f}")
                            st.write(f"- æœ€å°å€¼: {min_euclidean:.3f}")
                        else:
                            st.write("**æ¬§æ°è·ç¦»**: æ— æ•°æ®")
                
            else:
                st.info("æš‚æ— æ··åˆæ£€ç´¢ç»Ÿè®¡ä¿¡æ¯")

def display_knowledge_sources(retrieval_results: Dict[str, Any]):
    """å±•ç¤ºçŸ¥è¯†æ¥æº - é»˜è®¤æŠ˜å """
    # ä½¿ç”¨expanderå®ç°æŠ˜å åŠŸèƒ½ï¼Œé»˜è®¤æŠ˜å 
    with st.expander("ğŸ“š çŸ¥è¯†æ¥æº", expanded=False):
        # å¤„ç†SimpleRAGSystemçš„æ•°æ®æ ¼å¼
        search_results = retrieval_results.get('search_results', {})
        vector_search = search_results.get('vector_search', {})
        graph_search = search_results.get('graph_search', {})
        
        sources = []
        seen_sources = set()  # ç”¨äºå»é‡
        
        # æ”¶é›†å‘é‡æ£€ç´¢æ¥æº
        for entity in vector_search.get('entities', []):
            if entity.get('name'):
                source_key = f"vector_entity_{entity.get('name')}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å‘é‡å®ä½“',
                        'name': entity.get('name', 'N/A'),
                        'source': 'Weaviateå‘é‡æ•°æ®åº“',
                        'description': entity.get('description', 'N/A')
                    })
                    seen_sources.add(source_key)
        
        for relation in vector_search.get('relations', []):
            if relation.get('description'):
                desc = relation.get('description', 'N/A')[:50] + '...'
                source_key = f"vector_relation_{desc}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å‘é‡å…³ç³»',
                        'name': desc,
                        'source': 'Weaviateå‘é‡æ•°æ®åº“'
                    })
                    seen_sources.add(source_key)
        
        # æ”¶é›†å›¾è°±æ£€ç´¢æ¥æºï¼ˆå»é‡ï¼‰
        for node in graph_search.get('nodes', []):
            if node.get('name'):
                node_name = node.get('name', 'N/A')
                source_key = f"graph_node_{node_name}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å›¾è°±èŠ‚ç‚¹',
                        'name': node_name,
                        'source': 'Neo4jçŸ¥è¯†å›¾è°±',
                        'description': node.get('description', 'N/A'),
                        'labels': ', '.join(node.get('labels', []))
                    })
                    seen_sources.add(source_key)
        
        for rel in graph_search.get('relationships', []):
            if rel.get('type'):
                start_name = rel.get('start_node', {}).get('name', 'N/A')
                end_name = rel.get('end_node', {}).get('name', 'N/A')
                rel_name = f"{start_name} â†’ {rel.get('type', 'N/A')} â†’ {end_name}"
                source_key = f"graph_relation_{rel_name}"
                if source_key not in seen_sources:
                    sources.append({
                        'type': 'å›¾è°±å…³ç³»',
                        'name': rel_name,
                        'source': 'Neo4jçŸ¥è¯†å›¾è°±'
                    })
                    seen_sources.add(source_key)
        
        if sources:
            for i, source in enumerate(sources[:10], 1):
                # ä½¿ç”¨å®¹å™¨è€Œä¸æ˜¯åµŒå¥—expander
                with st.container():
                    st.markdown(f"**æ¥æº {i}: {source['name']}**")
                    st.write(f"ç±»å‹: {source['type']}")
                    st.write(f"æ•°æ®æº: {source['source']}")
                    if source.get('description') and source['description'] != 'N/A':
                        st.write(f"æè¿°: {source['description']}")
                    if source.get('labels'):
                        st.write(f"æ ‡ç­¾: {source['labels']}")
                    st.divider()
        else:
            st.info("æš‚æ— çŸ¥è¯†æ¥æºä¿¡æ¯")

def check_service_status():
    """æ£€æŸ¥å„æœåŠ¡çŠ¶æ€"""
    from config.settings import ConfigManager
    config = ConfigManager()
    
    services = {
        "Ollama": config.ollama.api_tags_url,
        "Neo4j": "http://localhost:7474",  # Neo4j Browserç«¯å£ï¼ˆå›ºå®šï¼‰
        "Weaviate": config.weaviate.meta_url
    }
    
    status = {}
    for service, url in services.items():
        try:
            response = requests.get(url, timeout=3)
            status[service] = response.status_code == 200
        except:
            status[service] = False
    
    return status

def display_service_status():
    """æ˜¾ç¤ºæœåŠ¡çŠ¶æ€"""
    st.subheader("ğŸ”§ æœåŠ¡çŠ¶æ€")
    
    status = check_service_status()
    
    for service, is_online in status.items():
        status_class = "status-online" if is_online else "status-offline"
        status_text = "åœ¨çº¿" if is_online else "ç¦»çº¿"
        
        st.markdown(f"""
        <div class="service-status">
            <div class="status-indicator {status_class}"></div>
            <strong>{service}</strong>: {status_text}
        </div>
        """, unsafe_allow_html=True)
    
    return status

@st.cache_resource
def initialize_llm():
    """åˆå§‹åŒ–LLMï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    return SimpleOllamaLLM()

@st.cache_resource
def initialize_retriever():
    """åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰"""
    logger.info(f"å¼€å§‹åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ŒREAL_RAG_AVAILABLE={REAL_RAG_AVAILABLE}")
    
    if REAL_RAG_AVAILABLE:
        logger.info("å°è¯•åˆå§‹åŒ–æ–°RAGç³»ç»Ÿ")
        rag_system = NewRAGSystem()
        if rag_system.initialized:
            logger.info("æ–°RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return rag_system
        else:
            logger.warning("æ–°RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ç®€åŒ–RAGç³»ç»Ÿ")
            if SIMPLE_RAG_AVAILABLE:
                rag_system = SimpleRAGSystem()
                if rag_system.initialized:
                    logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
                    return rag_system
            logger.warning("æ‰€æœ‰RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            return MockRAGRetriever()
    elif SIMPLE_RAG_AVAILABLE:
        logger.info("å°è¯•åˆå§‹åŒ–ç®€åŒ–RAGç³»ç»Ÿ")
        rag_system = SimpleRAGSystem()
        if rag_system.initialized:
            logger.info("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return rag_system
        else:
            logger.warning("ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            return MockRAGRetriever()
    else:
        logger.info("ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿ")
        return MockRAGRetriever()

def create_medical_prompt(question: str, retrieval_context: str = "") -> str:
    """åˆ›å»ºåŒ»ç–—é¢†åŸŸçš„æç¤ºè¯"""
    base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·åŸºäºåŒ»å­¦çŸ¥è¯†å’Œæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œç¡®ä¿å›ç­”å‡†ç¡®ã€ä¸“ä¸šä¸”æ˜“äºç†è§£ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}"""
    
    if retrieval_context:
        base_prompt += f"""

å‚è€ƒä¿¡æ¯ï¼š
{retrieval_context}"""
    
    base_prompt += """

è¯·æä¾›è¯¦ç»†çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å›ç­”é—®é¢˜
2. ç›¸å…³çš„åŒ»å­¦è§£é‡Š
3. æ³¨æ„äº‹é¡¹æˆ–å»ºè®®

æ³¨æ„ï¼šæœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç–—å»ºè®®ã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚

å›ç­”ï¼š"""
    
    return base_prompt

def format_retrieval_context(retrieval_results: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºä¸Šä¸‹æ–‡"""
    context_parts = []
    
    vector_results = retrieval_results.get("vector_results", [])
    for result in vector_results:
        context_parts.append(f"å®ä½“: {result.get('entity', 'N/A')}")
        context_parts.append(f"å†…å®¹: {result.get('content', 'N/A')}")
        context_parts.append(f"æ¥æº: {result.get('source', 'N/A')}")
        context_parts.append("---")
    
    return "\n".join(context_parts)

def main():
    """ä¸»å‡½æ•°"""
    # è·å–é…ç½®
    config = get_config()
    
    # é¡µé¢æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¥ åŒ»ç–—çŸ¥è¯†RAGç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'temperature' not in st.session_state:
        st.session_state.temperature = 0.7
    
    if 'max_tokens' not in st.session_state:
        st.session_state.max_tokens = 1000
    
    # ä½¿ç”¨ç¼“å­˜çš„åˆå§‹åŒ–å‡½æ•°ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
    with st.spinner("ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ..."):
        rag_system = initialize_retriever()
        
        # æ˜¾ç¤ºåˆå§‹åŒ–ç»“æœï¼ˆåªåœ¨é¦–æ¬¡åŠ è½½æ—¶æ˜¾ç¤ºï¼‰
        if 'init_message_shown' not in st.session_state:
            if isinstance(rag_system, NewRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… æ–°RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"å‘é‡å®ä½“ {stats.get('vector_entities', 0)} ä¸ª")
                else:
                    st.error("âŒ æ–°RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            elif isinstance(rag_system, SimpleRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"çŠ¶æ€: {stats.get('status', 'æœªçŸ¥')}")
                else:
                    st.error("âŒ ç®€åŒ–RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            elif isinstance(rag_system, RealRAGSystem):
                if rag_system.initialized:
                    st.success("âœ… çœŸå®RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                    
                    # æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡
                    stats = rag_system.get_stats()
                    if stats:
                        st.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: Neo4jèŠ‚ç‚¹ {stats.get('neo4j_nodes', 0)} ä¸ª, "
                               f"å…³ç³» {stats.get('neo4j_relationships', 0)} ä¸ª, "
                               f"å‘é‡å®ä½“ {stats.get('vector_entities', 0)} ä¸ª")
                else:
                    st.error("âŒ çœŸå®RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç³»ç»Ÿ")
            else:
                st.warning("âš ï¸ ä½¿ç”¨æ¨¡æ‹ŸRAGç³»ç»Ÿ")
            
            st.session_state.init_message_shown = True
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        
        # æœåŠ¡çŠ¶æ€
        service_status = display_service_status()
        
        st.divider()
        
        # æ¨¡å‹è®¾ç½®
        st.header("ğŸ¤– æ¨¡å‹è®¾ç½®")
        # ä»é…ç½®è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œå¦‚æœé…ç½®ä¸­æ²¡æœ‰å®šä¹‰åˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨
        available_models = getattr(config.ollama, 'available_models', ["gemma3:4b", "llama3:8b", "qwen2:7b"])
        default_model = config.ollama.default_model
        
        # ç¡®ä¿é»˜è®¤æ¨¡å‹åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
        if default_model not in available_models:
            available_models.insert(0, default_model)
        
        # è®¾ç½®é»˜è®¤é€‰ä¸­çš„æ¨¡å‹ç´¢å¼•
        default_index = available_models.index(default_model) if default_model in available_models else 0
        
        model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            available_models,
            index=default_index
        )
        
        st.session_state.temperature = st.slider(
            "æ¸©åº¦ (åˆ›é€ æ€§)",
            min_value=0.1,
            max_value=1.0,
            value=st.session_state.temperature,
            step=0.1
        )
        
        st.session_state.max_tokens = st.slider(
            "æœ€å¤§è¾“å‡ºé•¿åº¦",
            min_value=100,
            max_value=2000,
            value=st.session_state.max_tokens,
            step=100
        )
        
        st.divider()
        
        # ä½¿ç”¨è¯´æ˜
        st.header("ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥åŒ»ç–—ç›¸å…³é—®é¢˜
        2. ç³»ç»Ÿå°†æ£€ç´¢ç›¸å…³çŸ¥è¯†å¹¶ç”Ÿæˆä¸“ä¸šå›ç­”
        3. å¯åœ¨ä¾§è¾¹æ è°ƒæ•´æ¨¡å‹å‚æ•°
        4. æŸ¥çœ‹è¯¦ç»†çš„æ£€ç´¢è¿‡ç¨‹å’ŒçŸ¥è¯†æ¥æº
        """)
        
        st.divider()
        
        # ç³»ç»Ÿé…ç½®ä¿¡æ¯ï¼ˆç§»é™¤RAGç³»ç»ŸçŠ¶æ€ï¼‰
        st.header("âš™ï¸ å½“å‰é…ç½®")
        st.info(f"""
        **æ¨¡å‹è®¾ç½®:**
        - æ¨¡å‹: {model_name}
        - æ¸©åº¦: {st.session_state.temperature}
        - æœ€å¤§é•¿åº¦: {st.session_state.max_tokens}
        - æœåŠ¡ç«¯å£: 11434
        """)
        
        st.divider()
        
        # åŠŸèƒ½è¯´æ˜
        st.header("ğŸ” åŠŸèƒ½ç‰¹è‰²")
        st.markdown("""
        - **æ™ºèƒ½æ£€ç´¢**: åŸºäºçŸ¥è¯†å›¾è°±çš„ç²¾å‡†æ£€ç´¢
        - **å¤šç»´åº¦åˆ†æ**: å‘é‡+å›¾è°±+æ··åˆæ£€ç´¢
        - **æ£€ç´¢å¯è§†åŒ–**: è¯¦ç»†å±•ç¤ºæ£€ç´¢è¿‡ç¨‹
        - **ä¸“ä¸šé—®ç­”**: åŸºäºåŒ»ç–—çŸ¥è¯†çš„æ™ºèƒ½å›ç­”
        - **å‚æ•°è°ƒèŠ‚**: å¯è°ƒèŠ‚æ¨¡å‹åˆ›é€ æ€§å’Œé•¿åº¦
        """)
        
        # æ³¨æ„äº‹é¡¹
        st.warning("âš ï¸ æœ¬ç³»ç»Ÿä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼ŒåŒ»ç–—å»ºè®®è¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ")
    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")
        
        # æ£€æŸ¥Ollamaè¿æ¥
        if not service_status.get("Ollama", False):
            st.error("âŒ OllamaæœåŠ¡æœªè¿æ¥ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            st.stop()
        
        # åˆå§‹åŒ–LLM
        llm = initialize_llm()
        llm.model = model_name
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    with col2:
        st.header("ğŸ”§ åŠŸèƒ½é¢æ¿")
        
        # æ¸…ç©ºèŠå¤©å†å²
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
            st.session_state.messages = []
            st.success("èŠå¤©è®°å½•å·²æ¸…ç©ºï¼")
        
        st.divider()
        
        # ç¤ºä¾‹é—®é¢˜
        st.subheader("ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
        example_questions = [
            "å¸•é‡‘æ£®ç—…çš„ä¸»è¦ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ",
            "é«˜è¡€å‹çš„é¢„é˜²æªæ–½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç³–å°¿ç—…æ‚£è€…çš„é¥®é£Ÿæ³¨æ„äº‹é¡¹ï¼Ÿ",
            "å¦‚ä½•é¢„é˜²å¿ƒè„ç—…ï¼Ÿ",
            "æ„Ÿå†’å’Œæµæ„Ÿçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        for i, question in enumerate(example_questions):
            if st.button(question, key=f"example_{i}"):
                # è®¾ç½®ä¼šè¯çŠ¶æ€æ¥å¤„ç†ç¤ºä¾‹é—®é¢˜
                st.session_state.example_question = question
        
        st.divider()
        
        # ç»Ÿè®¡ä¿¡æ¯
        st.subheader("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
        user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
        assistant_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
        
        st.metric("ç”¨æˆ·æ¶ˆæ¯", user_messages)
        st.metric("AIå›å¤", assistant_messages)
    
    # å¤„ç†ç¤ºä¾‹é—®é¢˜
    if hasattr(st.session_state, 'example_question'):
        prompt = st.session_state.example_question
        del st.session_state.example_question
        
        # å¤„ç†é—®é¢˜çš„é€»è¾‘
        process_user_question(prompt, model_name, st.session_state.temperature, st.session_state.max_tokens)
    
    # ç”¨æˆ·è¾“å…¥ï¼ˆç§»åˆ°columnså¤–é¢ï¼‰
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„åŒ»ç–—ç›¸å…³é—®é¢˜..."):
        process_user_question(prompt, model_name, st.session_state.temperature, st.session_state.max_tokens)

def process_user_question(prompt: str, model_name: str, temperature: float, max_tokens: int):
    """å¤„ç†ç”¨æˆ·é—®é¢˜çš„ç»Ÿä¸€å‡½æ•° - ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ"""
    # ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²å¹¶æ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # ç«‹å³æ˜¾ç¤ºAIæ€è€ƒçŠ¶æ€
    with st.chat_message("assistant"):
        # åˆ›å»ºä¸€ä¸ªå®¹å™¨ç”¨äºè‡ªåŠ¨æ»šåŠ¨
        question_container = st.container()
        with question_container:
            # æ·»åŠ ä¸€ä¸ªç©ºçš„å ä½ç¬¦ï¼Œç”¨äºJavaScriptæ»šåŠ¨å®šä½
            st.markdown('<div id="question-anchor"></div>', unsafe_allow_html=True)
        
        # åˆ›å»ºå ä½ç¬¦ç”¨äºæµå¼æ›´æ–°
        thinking_placeholder = st.empty()
        thinking_placeholder.markdown("ğŸ¤– **æ€è€ƒä¸­...**")
        
        # æ£€æŸ¥Ollamaè¿æ¥ï¼ˆé™é»˜æ£€æŸ¥ï¼‰
        service_status = check_service_status()
        if not service_status.get("Ollama", False):
            thinking_placeholder.error("âŒ OllamaæœåŠ¡æœªè¿æ¥ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            return
        
        # åˆå§‹åŒ–ç»„ä»¶
        llm = initialize_llm()
        llm.model = model_name
        retriever = initialize_retriever()  # ä½¿ç”¨ç¼“å­˜çš„åˆå§‹åŒ–å‡½æ•°
        
        # æ›´æ–°æ€è€ƒçŠ¶æ€
        thinking_placeholder.markdown("ğŸ” **æ­£åœ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†...**")
        
        # æ‰§è¡Œæ£€ç´¢
        try:
            retrieval_results = retriever.search_knowledge(prompt)
            
            # æ›´æ–°æ€è€ƒçŠ¶æ€
            thinking_placeholder.markdown("ğŸ§  **æ­£åœ¨åˆ†ææ£€ç´¢ç»“æœ...**")
            
            # åˆ›å»ºå®Œæ•´å“åº”çš„å ä½ç¬¦
            response_placeholder = st.empty()
            
            # æ„å»ºå®Œæ•´å“åº”å†…å®¹
            with response_placeholder.container():
                # æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹
                display_retrieval_process(retrieval_results)
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                display_detailed_results(retrieval_results)
                
                # æ˜¾ç¤ºçŸ¥è¯†æ¥æº
                display_knowledge_sources(retrieval_results)
                
                # æ›´æ–°æ€è€ƒçŠ¶æ€ä¸ºç”Ÿæˆå›ç­”
                thinking_placeholder.markdown("âœï¸ **æ­£åœ¨ç”Ÿæˆä¸“ä¸šå›ç­”...**")
                
                # ç”Ÿæˆå›ç­”
                if isinstance(retriever, (SimpleRAGSystem, RealRAGSystem)) and hasattr(retriever, 'generate_answer'):
                    # ç®€åŒ–æˆ–çœŸå®RAGç³»ç»Ÿ
                    response = retriever.generate_answer(prompt, retrieval_results)
                else:
                    # æ¨¡æ‹ŸRAGç³»ç»Ÿ - ä½¿ç”¨ç®€å•LLM
                    retrieval_context = format_retrieval_context(retrieval_results)
                    medical_prompt = create_medical_prompt(prompt, retrieval_context)
                    response = llm.generate_response(medical_prompt, temperature, max_tokens)
                
                # æ¸…é™¤æ€è€ƒçŠ¶æ€ï¼Œæ˜¾ç¤ºæœ€ç»ˆå›ç­”
                thinking_placeholder.empty()
                
                # æ˜¾ç¤ºAIå›ç­”
                st.markdown("### ğŸ¤– AIå›ç­”")
                
                # æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ
                answer_placeholder = st.empty()
                
                # åˆ†æ®µæ˜¾ç¤ºå›ç­”ï¼ˆæ¨¡æ‹Ÿæµå¼æ•ˆæœï¼‰
                words = response.split()
                displayed_text = ""
                
                for i, word in enumerate(words):
                    displayed_text += word + " "
                    if i % 3 == 0:  # æ¯3ä¸ªè¯æ›´æ–°ä¸€æ¬¡
                        answer_placeholder.markdown(displayed_text)
                        time.sleep(0.05)  # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹Ÿæµå¼æ•ˆæœ
                
                # æ˜¾ç¤ºå®Œæ•´å›ç­”
                answer_placeholder.markdown(response)
                
                # æ„å»ºå®Œæ•´çš„å†å²è®°å½•
                search_results = retrieval_results.get('search_results', {})
                graph_search = search_results.get('graph_search', {})
                vector_search = search_results.get('vector_search', {})
                
                full_response = f"""### ğŸ” æ£€ç´¢ç»“æœ
- å‘é‡æ£€ç´¢: {len(vector_search.get('entities', []))} ä¸ªå®ä½“
- å›¾è°±æ£€ç´¢: {len(graph_search.get('nodes', []))} ä¸ªèŠ‚ç‚¹
- æ£€ç´¢è€—æ—¶: {retrieval_results.get('retrieval_time', 'N/A')}s

### ğŸ¤– AIå›ç­”
{response}
"""
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
                # æ·»åŠ JavaScriptè‡ªåŠ¨æ»šåŠ¨åˆ°é—®é¢˜ä½ç½®
                st.markdown("""
                <script>
                setTimeout(function() {
                    const anchor = document.getElementById('question-anchor');
                    if (anchor) {
                        anchor.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                }, 100);
                </script>
                """, unsafe_allow_html=True)
                
        except Exception as e:
            thinking_placeholder.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            logger.error(f"å¤„ç†ç”¨æˆ·é—®é¢˜æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    main()