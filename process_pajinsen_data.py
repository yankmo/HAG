#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸•é‡‘æ£®ç—…æ–‡æœ¬æ•°æ®å¤„ç†å’ŒNeo4jå­˜å‚¨è„šæœ¬
å°†å¸•é‡‘æ£®ç—…ç›¸å…³æ–‡æœ¬æ•°æ®æå–å®ä½“å’Œå…³ç³»ï¼Œå¹¶å­˜å‚¨åˆ°Neo4jå‘é‡æ•°æ®åº“
"""

import sys
import os
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from src.knowledge.neo4j_vector_storage import Neo4jVectorStore, Neo4jVectorEntity, Neo4jVectorRelation
from src.knowledge.intent_recognition_neo4j import IntentRecognizer, OllamaClient
from src.services.embedding_service import OllamaEmbeddingService
from config import get_config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pajinsen_processing.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PajinsenDataProcessor:
    """å¸•é‡‘æ£®ç—…æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        try:
            # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
            self.vector_storage = Neo4jVectorStore()
            self.ollama_client = OllamaClient()
            self.intent_recognizer = IntentRecognizer(self.ollama_client)
            self.embedding_service = OllamaEmbeddingService()
            
            logger.info("å¸•é‡‘æ£®ç—…æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        try:
            logger.info("æ­£åœ¨æ¸…ç©ºNeo4jæ•°æ®åº“...")
            self.vector_storage.clear_database()
            logger.info("æ•°æ®åº“æ¸…ç©ºå®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    def split_text(self, text: str, chunk_size: int = 800) -> list:
        """æ™ºèƒ½åˆ†å‰²æ–‡æœ¬"""
        # æ¸…ç†æ–‡æœ¬
        text = text.strip()
        
        # æŒ‰æ®µè½å’Œç« èŠ‚åˆ†å‰²
        sections = []
        current_section = ""
        
        lines = text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜ï¼ˆä»¥==å¼€å¤´å’Œç»“å°¾ï¼‰
            if line.startswith('==') and line.endswith('=='):
                if current_section:
                    sections.append(current_section.strip())
                current_section = line + "\n"
            else:
                current_section += line + "\n"
        
        if current_section:
            sections.append(current_section.strip())
        
        # è¿›ä¸€æ­¥åˆ†å‰²è¿‡é•¿çš„ç« èŠ‚
        chunks = []
        for section in sections:
            if len(section) <= chunk_size:
                chunks.append(section)
            else:
                # æŒ‰æ®µè½åˆ†å‰²é•¿ç« èŠ‚
                paragraphs = section.split('\n\n')
                current_chunk = ""
                
                for paragraph in paragraphs:
                    if len(current_chunk) + len(paragraph) <= chunk_size:
                        if current_chunk:
                            current_chunk += "\n\n" + paragraph
                        else:
                            current_chunk = paragraph
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = paragraph
                
                if current_chunk:
                    chunks.append(current_chunk.strip())
        
        # è¿‡æ»¤ç©ºå—
        chunks = [chunk for chunk in chunks if chunk.strip()]
        return chunks
    
    def process_text_file(self, file_path: str):
        """å¤„ç†æ–‡æœ¬æ–‡ä»¶"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            
            # æ¸…ç©ºæ•°æ®åº“
            self.clear_database()
            
            # åˆ†å‰²æ–‡æœ¬
            chunks = self.split_text(content)
            logger.info(f"æ–‡æœ¬åˆ†ä¸º {len(chunks)} ä¸ªå—")
            
            # ç»Ÿè®¡å˜é‡
            total_entities = 0
            total_relations = 0
            all_vector_entities = []
            all_vector_relations = []
            
            # å¤„ç†æ¯ä¸ªæ–‡æœ¬å—
            for i, chunk in enumerate(chunks):
                logger.info(f"å¤„ç†ç¬¬ {i+1}/{len(chunks)} å— (é•¿åº¦: {len(chunk)} å­—ç¬¦)")
                
                try:
                    # æå–å®ä½“å’Œå…³ç³»
                    entities, relations = self.intent_recognizer.extract_entities_and_relations(chunk)
                    
                    if entities:
                        logger.info(f"å— {i+1}: æå–åˆ° {len(entities)} ä¸ªå®ä½“")
                        
                        # è½¬æ¢ä¸ºå‘é‡å®ä½“
                        for entity in entities:
                            # ç”Ÿæˆå®ä½“æè¿°æ–‡æœ¬
                            entity_text = f"å®ä½“: {entity.name}, ç±»å‹: {entity.type}"
                            if entity.properties and entity.properties.get("description"):
                                entity_text += f", æè¿°: {entity.properties['description']}"
                            
                            # å‘é‡åŒ–
                            vector = self.embedding_service.embed_text(entity_text)
                            if vector:
                                vector_entity = Neo4jVectorEntity(
                                    name=entity.name,
                                    type=entity.type,
                                    properties=entity.properties or {},
                                    vector=vector,
                                    source_text=chunk[:200] + "..." if len(chunk) > 200 else chunk
                                )
                                all_vector_entities.append(vector_entity)
                                total_entities += 1
                    
                    if relations:
                        logger.info(f"å— {i+1}: æå–åˆ° {len(relations)} ä¸ªå…³ç³»")
                        
                        # è½¬æ¢ä¸ºå‘é‡å…³ç³»
                        for relation in relations:
                            # ç”Ÿæˆå…³ç³»æè¿°æ–‡æœ¬
                            relation_text = f"å…³ç³»: {relation.source} {relation.relation_type} {relation.target}"
                            if relation.properties and relation.properties.get("description"):
                                relation_text += f", æè¿°: {relation.properties['description']}"
                            
                            # å‘é‡åŒ–
                            vector = self.embedding_service.embed_text(relation_text)
                            if vector:
                                vector_relation = Neo4jVectorRelation(
                                    source=relation.source,
                                    target=relation.target,
                                    relation_type=relation.relation_type,
                                    description=relation.properties.get('description', '') if relation.properties else '',
                                    vector=vector,
                                    source_text=chunk[:200] + "..." if len(chunk) > 200 else chunk
                                )
                                all_vector_relations.append(vector_relation)
                                total_relations += 1
                    
                    if not entities and not relations:
                        logger.warning(f"å— {i+1}: æœªæå–åˆ°ä»»ä½•å®ä½“æˆ–å…³ç³»")
                        
                except Exception as e:
                    logger.error(f"å¤„ç†å— {i+1} æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
            # æ‰¹é‡å­˜å‚¨åˆ°Neo4j
            logger.info(f"å¼€å§‹å­˜å‚¨æ•°æ®åˆ°Neo4j...")
            logger.info(f"å‡†å¤‡å­˜å‚¨ {len(all_vector_entities)} ä¸ªå®ä½“å‘é‡")
            logger.info(f"å‡†å¤‡å­˜å‚¨ {len(all_vector_relations)} ä¸ªå…³ç³»å‘é‡")
            
            # å­˜å‚¨å®ä½“
            if all_vector_entities:
                success = self.vector_storage.store_entities(all_vector_entities)
                if success:
                    logger.info(f"æˆåŠŸå­˜å‚¨ {len(all_vector_entities)} ä¸ªå®ä½“å‘é‡")
                else:
                    logger.error("å®ä½“å‘é‡å­˜å‚¨å¤±è´¥")
            
            # å­˜å‚¨å…³ç³»
            if all_vector_relations:
                success = self.vector_storage.store_relations(all_vector_relations)
                if success:
                    logger.info(f"æˆåŠŸå­˜å‚¨ {len(all_vector_relations)} ä¸ªå…³ç³»å‘é‡")
                else:
                    logger.error("å…³ç³»å‘é‡å­˜å‚¨å¤±è´¥")
            
            # è·å–æœ€ç»ˆç»Ÿè®¡
            stats = self.vector_storage.get_statistics()
            
            logger.info("=" * 60)
            logger.info("å¸•é‡‘æ£®ç—…æ•°æ®å¤„ç†å®Œæˆï¼")
            logger.info(f"å¤„ç†çš„æ–‡æœ¬å—æ•°: {len(chunks)}")
            logger.info(f"æå–çš„å®ä½“æ€»æ•°: {total_entities}")
            logger.info(f"æå–çš„å…³ç³»æ€»æ•°: {total_relations}")
            logger.info("=" * 60)
            logger.info("Neo4jå­˜å‚¨ç»Ÿè®¡:")
            logger.info(f"  Neo4jèŠ‚ç‚¹æ•°: {stats['neo4j_nodes']}")
            logger.info(f"  Neo4jå…³ç³»æ•°: {stats['neo4j_relationships']}")
            logger.info(f"  å‘é‡å®ä½“æ•°: {stats['vector_entities']}")
            logger.info(f"  å‘é‡å…³ç³»æ•°: {stats['vector_relations']}")
            logger.info("=" * 60)
            
            return {
                "chunks_processed": len(chunks),
                "entities_extracted": total_entities,
                "relations_extracted": total_relations,
                "neo4j_stats": stats
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise
    
    def test_retrieval(self, query: str = "å¸•é‡‘æ£®ç—…çš„ç—‡çŠ¶"):
        """æµ‹è¯•æ£€ç´¢åŠŸèƒ½"""
        try:
            logger.info(f"æµ‹è¯•æ£€ç´¢åŠŸèƒ½ï¼ŒæŸ¥è¯¢: {query}")
            
            # å®ä½“æ£€ç´¢
            entity_results = self.vector_storage.search_entities(query, limit=5)
            logger.info(f"å®ä½“æ£€ç´¢ç»“æœ: {len(entity_results)} ä¸ª")
            for i, result in enumerate(entity_results):
                logger.info(f"  {i+1}. {result['name']} ({result['type']}) - ç›¸ä¼¼åº¦: {result['similarity']:.3f}")
            
            # å…³ç³»æ£€ç´¢
            relation_results = self.vector_storage.search_relations(query, limit=5)
            logger.info(f"å…³ç³»æ£€ç´¢ç»“æœ: {len(relation_results)} ä¸ª")
            for i, result in enumerate(relation_results):
                logger.info(f"  {i+1}. {result['source']} -> {result['target']} ({result['relation_type']}) - ç›¸ä¼¼åº¦: {result['similarity']:.3f}")
            
            # æ··åˆæ£€ç´¢
            hybrid_results = self.vector_storage.search_entities_hybrid(query, limit=3)
            logger.info(f"æ··åˆæ£€ç´¢ç»“æœ: {len(hybrid_results)} ä¸ª")
            for i, result in enumerate(hybrid_results):
                logger.info(f"  {i+1}. {result['name']} ({result['type']}) - æ··åˆåˆ†æ•°: {result['score']:.3f}")
            
        except Exception as e:
            logger.error(f"æµ‹è¯•æ£€ç´¢å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå¤„ç†å™¨
        processor = PajinsenDataProcessor()
        
        # å¤„ç†å¸•é‡‘æ£®ç—…æ–‡æœ¬æ–‡ä»¶
        file_path = "e:/Program/Project/HAG/data/pajinsen.txt"
        
        if not os.path.exists(file_path):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        # å¤„ç†æ–‡ä»¶
        results = processor.process_text_file(file_path)
        
        # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
        logger.info("\n" + "=" * 60)
        logger.info("æµ‹è¯•æ£€ç´¢åŠŸèƒ½")
        logger.info("=" * 60)
        
        test_queries = [
            "å¸•é‡‘æ£®ç—…çš„ç—‡çŠ¶",
            "å¸•é‡‘æ£®ç—…çš„æ²»ç–—æ–¹æ³•",
            "å¸•é‡‘æ£®ç—…çš„ç—…å› ",
            "å¤šå·´èƒº",
            "éœ‡é¢¤"
        ]
        
        for query in test_queries:
            logger.info(f"\næŸ¥è¯¢: {query}")
            processor.test_retrieval(query)
        
        print("\nâœ… å¸•é‡‘æ£®ç—…æ•°æ®å¤„ç†å’Œå­˜å‚¨å®Œæˆï¼")
        print("ğŸ“Š è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹ pajinsen_processing.log æ–‡ä»¶")
        print("ğŸ”— å¯ä»¥åœ¨Neo4j Browserä¸­æŸ¥çœ‹å­˜å‚¨çš„çŸ¥è¯†å›¾è°±: http://localhost:7474")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()