#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ··åˆRAGç³»ç»Ÿ - é›†æˆæ„å›¾è¯†åˆ«ã€Neo4jçŸ¥è¯†å›¾è°±å’Œå‘é‡å­˜å‚¨
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.knowledge.intent_recognition_neo4j import KnowledgeGraphBuilder, Entity, Relation
from src.knowledge.vector_storage import (
    OllamaEmbeddingClient, 
    WeaviateVectorStore, 
    VectorKnowledgeProcessor,
    VectorEntity,
    VectorRelation
)
import logging
from typing import List, Dict, Any, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HybridRAGSystem:
    """æ··åˆRAGç³»ç»Ÿ"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.kg_builder = KnowledgeGraphBuilder()
        self.embedding_client = OllamaEmbeddingClient(model="bgm-m3:latest")
        self.vector_store = WeaviateVectorStore()
        self.vector_processor = VectorKnowledgeProcessor(self.embedding_client, self.vector_store)
        
        logger.info("æ··åˆRAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def setup_vector_storage(self):
        """è®¾ç½®å‘é‡å­˜å‚¨"""
        logger.info("è®¾ç½®Weaviateå‘é‡å­˜å‚¨...")
        self.vector_store.setup_collections()
        logger.info("å‘é‡å­˜å‚¨è®¾ç½®å®Œæˆ")
    
    def build_knowledge_graph(self, file_path: str, chunk_size: int = 500):
        """æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆåŒ…å«Neo4jå’Œå‘é‡å­˜å‚¨ï¼‰"""
        try:
            logger.info(f"å¼€å§‹æ„å»ºæ··åˆçŸ¥è¯†å›¾è°±: {file_path}")
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            
            # æ¸…ç©ºNeo4jæ•°æ®åº“
            self.kg_builder.importer.clear_database()
            
            # è®¾ç½®å‘é‡å­˜å‚¨
            self.setup_vector_storage()
            
            # åˆ†å—å¤„ç†æ–‡æœ¬
            chunks = self.kg_builder._split_text(content, chunk_size)
            logger.info(f"æ–‡æœ¬åˆ†ä¸º {len(chunks)} ä¸ªå—")
            
            all_entities = []
            all_relations = []
            all_vector_entities = []
            all_vector_relations = []
            
            for i, chunk in enumerate(chunks):
                logger.info(f"å¤„ç†ç¬¬ {i+1}/{len(chunks)} å—")
                
                try:
                    # 1. ä½¿ç”¨Ollamaæå–å®ä½“å’Œå…³ç³»
                    entities, relations = self.kg_builder.recognizer.extract_entities_and_relations(chunk)
                    
                    if entities or relations:
                        # 2. å‘é‡åŒ–å®ä½“å’Œå…³ç³»
                        vector_entities, vector_relations = self.vector_processor.process_entities_and_relations(
                            entities, relations, chunk
                        )
                        
                        # æ”¶é›†æ‰€æœ‰æ•°æ®
                        all_entities.extend(entities)
                        all_relations.extend(relations)
                        all_vector_entities.extend(vector_entities)
                        all_vector_relations.extend(vector_relations)
                        
                        logger.info(f"å— {i+1}: æå–åˆ° {len(entities)} ä¸ªå®ä½“, {len(relations)} ä¸ªå…³ç³»")
                        logger.info(f"å— {i+1}: å‘é‡åŒ– {len(vector_entities)} ä¸ªå®ä½“, {len(vector_relations)} ä¸ªå…³ç³»")
                    else:
                        logger.warning(f"å— {i+1}: æœªæå–åˆ°ä»»ä½•å®ä½“æˆ–å…³ç³»")
                        
                except Exception as e:
                    logger.error(f"å¤„ç†å— {i+1} æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            
            # å»é‡
            unique_entities = self.kg_builder._deduplicate_entities(all_entities)
            unique_relations = self.kg_builder._deduplicate_relations(all_relations)
            
            logger.info(f"å»é‡å: {len(unique_entities)} ä¸ªå®ä½“, {len(unique_relations)} ä¸ªå…³ç³»")
            
            # 3. å­˜å‚¨åˆ°Neo4j
            logger.info("æ­£åœ¨å­˜å‚¨åˆ°Neo4j...")
            self.kg_builder.importer.import_entities_and_relations(unique_entities, unique_relations)
            
            # 4. å­˜å‚¨å‘é‡åˆ°Weaviate
            logger.info("æ­£åœ¨å­˜å‚¨å‘é‡åˆ°Weaviate...")
            success = self.vector_processor.store_vectors(all_vector_entities, all_vector_relations)
            
            if success:
                logger.info("å‘é‡å­˜å‚¨æˆåŠŸ")
            else:
                logger.error("å‘é‡å­˜å‚¨å¤±è´¥")
            
            # è·å–å­˜å‚¨ç»Ÿè®¡
            stats = self.vector_store.get_collection_stats()
            logger.info(f"Weaviateå­˜å‚¨ç»Ÿè®¡: {stats['entities']} ä¸ªå®ä½“å‘é‡, {stats['relations']} ä¸ªå…³ç³»å‘é‡")
            
            logger.info("æ··åˆçŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
            
            return {
                "neo4j_entities": len(unique_entities),
                "neo4j_relations": len(unique_relations),
                "vector_entities": stats['entities'],
                "vector_relations": stats['relations']
            }
            
        except Exception as e:
            logger.error(f"æ„å»ºçŸ¥è¯†å›¾è°±å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return None
    
    def hybrid_search(self, query: str, entity_limit: int = 5, relation_limit: int = 5) -> Dict[str, Any]:
        """æ··åˆæœç´¢"""
        try:
            logger.info(f"æ‰§è¡Œæ··åˆæœç´¢: {query}")
            
            # 1. å‘é‡æœç´¢
            search_results = self.vector_processor.search_knowledge(
                query, entity_limit, relation_limit
            )
            
            # 2. æå–ç›¸å…³å®ä½“åç§°ç”¨äºNeo4jå›¾éå†
            relevant_entity_names = []
            for entity in search_results["entities"]:
                relevant_entity_names.append(entity["name"])
            
            # 3. åœ¨Neo4jä¸­æ‰©å±•å­å›¾ï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥æ›´å¤æ‚ï¼‰
            subgraph_info = self._expand_subgraph_from_neo4j(relevant_entity_names)
            
            return {
                "query": query,
                "vector_search": search_results,
                "subgraph": subgraph_info,
                "relevant_entities": relevant_entity_names
            }
            
        except Exception as e:
            logger.error(f"æ··åˆæœç´¢å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _expand_subgraph_from_neo4j(self, entity_names: List[str]) -> Dict[str, Any]:
        """ä»Neo4jæ‰©å±•å­å›¾"""
        try:
            if not entity_names:
                return {"nodes": [], "relationships": []}
            
            # æ„å»ºCypheræŸ¥è¯¢
            entity_list = "', '".join(entity_names)
            cypher_query = f"""
            MATCH (n)
            WHERE n.name IN ['{entity_list}']
            OPTIONAL MATCH (n)-[r]-(m)
            RETURN n, r, m
            LIMIT 50
            """
            
            result = self.kg_builder.importer.graph.run(cypher_query)
            
            nodes = []
            relationships = []
            
            for record in result:
                # æ·»åŠ èŠ‚ç‚¹
                if record["n"]:
                    node_data = dict(record["n"])
                    node_data["labels"] = list(record["n"].labels)
                    if node_data not in nodes:
                        nodes.append(node_data)
                
                if record["m"]:
                    node_data = dict(record["m"])
                    node_data["labels"] = list(record["m"].labels)
                    if node_data not in nodes:
                        nodes.append(node_data)
                
                # æ·»åŠ å…³ç³»
                if record["r"]:
                    rel_data = {
                        "type": type(record["r"]).__name__,
                        "properties": dict(record["r"]),
                        "start_node": dict(record["n"]) if record["n"] else None,
                        "end_node": dict(record["m"]) if record["m"] else None
                    }
                    relationships.append(rel_data)
            
            return {
                "nodes": nodes,
                "relationships": relationships,
                "total_nodes": len(nodes),
                "total_relationships": len(relationships)
            }
            
        except Exception as e:
            logger.error(f"æ‰©å±•å­å›¾å¤±è´¥: {e}")
            return {"nodes": [], "relationships": [], "error": str(e)}
    
    def generate_answer(self, query: str, search_results: Dict[str, Any]) -> str:
        """åŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            
            # æ·»åŠ å‘é‡æœç´¢çš„å®ä½“ä¿¡æ¯
            if search_results.get("vector_search", {}).get("entities"):
                context_parts.append("ç›¸å…³å®ä½“:")
                for entity in search_results["vector_search"]["entities"][:3]:
                    context_parts.append(f"- {entity['name']} ({entity['type']})")
            
            # æ·»åŠ å‘é‡æœç´¢çš„å…³ç³»ä¿¡æ¯
            if search_results.get("vector_search", {}).get("relations"):
                context_parts.append("ç›¸å…³å…³ç³»:")
                for relation in search_results["vector_search"]["relations"][:3]:
                    context_parts.append(f"- {relation['source']} {relation['relation_type']} {relation['target']}")
            
            # æ·»åŠ å­å›¾ä¿¡æ¯
            if search_results.get("subgraph", {}).get("nodes"):
                context_parts.append(f"çŸ¥è¯†å›¾è°±ä¸­æ‰¾åˆ° {len(search_results['subgraph']['nodes'])} ä¸ªç›¸å…³èŠ‚ç‚¹")
            
            context = "\n".join(context_parts)
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""åŸºäºä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

é—®é¢˜: {query}

ç›¸å…³çŸ¥è¯†:
{context}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜ã€‚"""

            # ä½¿ç”¨Ollamaç”Ÿæˆå›ç­”
            response = self.kg_builder.ollama.generate(prompt)
            
            return response
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯: {e}"
    
    def chat(self, query: str) -> Dict[str, Any]:
        """å®Œæ•´çš„å¯¹è¯æµç¨‹"""
        try:
            # 1. æ··åˆæœç´¢
            search_results = self.hybrid_search(query)
            
            # 2. ç”Ÿæˆç­”æ¡ˆ
            answer = self.generate_answer(query, search_results)
            
            return {
                "query": query,
                "answer": answer,
                "search_results": search_results,
                "timestamp": str(datetime.now())
            }
            
        except Exception as e:
            logger.error(f"å¯¹è¯å¤„ç†å¤±è´¥: {e}")
            return {
                "query": query,
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {e}",
                "error": str(e)
            }

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ··åˆRAGç³»ç»Ÿ
        rag_system = HybridRAGSystem()
        
        # æ„å»ºçŸ¥è¯†å›¾è°±
        file_path = "e:/Program/Project/rag-first/data/pajinsen.txt"
        logger.info("å¼€å§‹æ„å»ºæ··åˆçŸ¥è¯†å›¾è°±...")
        
        stats = rag_system.build_knowledge_graph(file_path)
        
        if stats:
            print("âœ… æ··åˆçŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼")
            print(f"ğŸ“Š Neo4j: {stats['neo4j_entities']} ä¸ªå®ä½“, {stats['neo4j_relations']} ä¸ªå…³ç³»")
            print(f"ğŸ” Weaviate: {stats['vector_entities']} ä¸ªå®ä½“å‘é‡, {stats['vector_relations']} ä¸ªå…³ç³»å‘é‡")
            print("ğŸ”— Neo4j Browser: http://localhost:7474")
            print("ğŸ”— Weaviate: http://localhost:8080")
            
            # æµ‹è¯•æœç´¢åŠŸèƒ½
            print("\nğŸ” æµ‹è¯•æ··åˆæœç´¢...")
            test_query = "å¸•é‡‘æ£®ç—…çš„ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ"
            search_results = rag_system.hybrid_search(test_query)
            print(f"æœç´¢æŸ¥è¯¢: {test_query}")
            print(f"æ‰¾åˆ° {len(search_results.get('vector_search', {}).get('entities', []))} ä¸ªç›¸å…³å®ä½“")
            print(f"æ‰¾åˆ° {len(search_results.get('vector_search', {}).get('relations', []))} ä¸ªç›¸å…³å…³ç³»")
            
        else:
            print("âŒ çŸ¥è¯†å›¾è°±æ„å»ºå¤±è´¥")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    from datetime import datetime
    main()