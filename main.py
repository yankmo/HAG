#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºLangChainçš„RAGä¸»ç¨‹åº
æ•´åˆç°æœ‰çš„æ£€ç´¢åŠŸèƒ½ï¼Œå®ç°å®Œæ•´çš„é—®ç­”æµç¨‹
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from langchain.schema import BaseRetriever, Document
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.llms.base import LLM
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from typing import List, Dict, Any, Optional
import json
import time
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„RAGç³»ç»Ÿ
from src.knowledge.modular_rag_system import ModularRAGSystem
import ollama
from ollama import Message

# å¯¼å…¥é…ç½®ç®¡ç†å™¨
from config import get_config

class OllamaLLM(LLM):
    """è‡ªå®šä¹‰Ollama LLMåŒ…è£…å™¨"""
    
    def __init__(self, model_name: str = None, base_url: str = None):
        super().__init__()
        config = get_config()
        self.model_name = model_name or config.ollama.default_model
        self.base_url = base_url or config.ollama.base_url
    
    @property
    def _llm_type(self) -> str:
        return "ollama"
    
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        """è°ƒç”¨Ollamaæ¨¡å‹ç”Ÿæˆå›ç­”"""
        try:
            import requests
            import json
            
            # æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code != 200:
                return "OllamaæœåŠ¡æœªè¿è¡Œï¼Œè¯·å¯åŠ¨OllamaæœåŠ¡åé‡è¯•ã€‚"
            
            # ä½¿ç”¨HTTP APIç›´æ¥è°ƒç”¨
            url = f"{self.base_url}/api/generate"
            data = {
                "model": self.model_name,
                "prompt": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„çŸ¥è¯†ç®€æ´å‡†ç¡®åœ°å›ç­”é—®é¢˜ã€‚\n\nç”¨æˆ·é—®é¢˜: {prompt}\n\nè¯·å›ç­”:",
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": 1000
                }
            }
            
            response = requests.post(url, json=data, timeout=60)
            if response.status_code == 200:
                result = response.json()
                return result.get('response', 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚')
            else:
                return f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}"
                
        except requests.exceptions.RequestException as e:
            return f"æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {str(e)}"
        except Exception as e:
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"

class RAGRetriever(BaseRetriever):
    """è‡ªå®šä¹‰RAGæ£€ç´¢å™¨"""
    
    def __init__(self, rag_system: ModularRAGSystem, **kwargs):
        super().__init__(**kwargs)
        # ä½¿ç”¨object.__setattr__æ¥ç»•è¿‡Pydanticçš„é™åˆ¶
        object.__setattr__(self, 'rag_system', rag_system)
        object.__setattr__(self, '_last_retrieval_details', {})
    
    @property
    def last_retrieval_details(self):
        return getattr(self, '_last_retrieval_details', {})
    
    def set_retrieval_details(self, details):
        object.__setattr__(self, '_last_retrieval_details', details)
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """æ‰§è¡Œæ£€ç´¢å¹¶è¿”å›ç›¸å…³æ–‡æ¡£"""
        try:
            # 1. å‘é‡æœç´¢
            print(f"\nğŸ” æ‰§è¡Œå‘é‡æœç´¢...")
            vector_results = self.rag_system.retrieval_manager.vector_search(
                query, entity_limit=5, relation_limit=5
            )
            
            # 2. å›¾è°±æœç´¢
            print(f"ğŸ•¸ï¸ æ‰§è¡Œå›¾è°±æœç´¢...")
            graph_results = self.rag_system.retrieval_manager.graph_search_topk_nodes(
                query, top_k=5, include_relations=True
            )
            
            # 3. æ··åˆæœç´¢
            print(f"ğŸ”„ æ‰§è¡Œæ··åˆæœç´¢...")
            hybrid_results = self.rag_system.search_manager.hybrid_search(
                query, vector_entity_limit=5, graph_top_k=5
            )
            
            # ä¿å­˜æ£€ç´¢è¯¦æƒ…ç”¨äºå±•ç¤º
            self.set_retrieval_details({
                'vector_results': vector_results,
                'graph_results': graph_results,
                'hybrid_results': hybrid_results,
                'query': query,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            
            # æ„å»ºæ–‡æ¡£åˆ—è¡¨
            documents = []
            
            # æ·»åŠ å‘é‡æœç´¢çš„å®ä½“
            for entity in vector_results.get('entities', []):
                content = f"å®ä½“: {entity.get('name', '')} - {entity.get('description', '')}"
                documents.append(Document(
                    page_content=content,
                    metadata={'type': 'vector_entity', 'source': 'vector_search'}
                ))
            
            # æ·»åŠ å‘é‡æœç´¢çš„å…³ç³»
            for relation in vector_results.get('relations', []):
                content = f"å…³ç³»: {relation.get('description', '')}"
                documents.append(Document(
                    page_content=content,
                    metadata={'type': 'vector_relation', 'source': 'vector_search'}
                ))
            
            # æ·»åŠ å›¾è°±æœç´¢çš„èŠ‚ç‚¹
            for node in graph_results.get('nodes', []):
                content = f"èŠ‚ç‚¹: {node.get('name', '')} - {node.get('properties', {})}"
                documents.append(Document(
                    page_content=content,
                    metadata={'type': 'graph_node', 'source': 'graph_search'}
                ))
            
            # æ·»åŠ å›¾è°±æœç´¢çš„å…³ç³»
            for rel in graph_results.get('relationships', []):
                content = f"å…³ç³»: {rel.get('type', '')} - {rel.get('properties', {})}"
                documents.append(Document(
                    page_content=content,
                    metadata={'type': 'graph_relation', 'source': 'graph_search'}
                ))
            
            return documents
            
        except Exception as e:
            print(f"âŒ æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return []

def format_retrieval_results(retriever: RAGRetriever) -> str:
    """æ ¼å¼åŒ–æ£€ç´¢ç»“æœç”¨äºå±•ç¤º"""
    details = retriever.last_retrieval_details
    if not details:
        return "æ— æ£€ç´¢è¯¦æƒ…"
    
    result_text = f"\nğŸ“Š æ£€ç´¢è¯¦æƒ… (æŸ¥è¯¢: {details['query']}, æ—¶é—´: {details['timestamp']})\n"
    result_text += "=" * 80 + "\n"
    
    # å‘é‡æœç´¢ç»“æœ
    vector_results = details.get('vector_results', {})
    result_text += f"\nğŸ” å‘é‡æœç´¢ç»“æœ:\n"
    result_text += f"  - å®ä½“æ•°é‡: {len(vector_results.get('entities', []))}\n"
    result_text += f"  - å…³ç³»æ•°é‡: {len(vector_results.get('relations', []))}\n"
    
    for i, entity in enumerate(vector_results.get('entities', [])[:3], 1):
        similarity = entity.get('similarity', 'N/A')
        if isinstance(similarity, (int, float)):
            result_text += f"  - å®ä½“{i}: {entity.get('name', 'N/A')} (ç›¸ä¼¼åº¦: {similarity:.3f})\n"
        else:
            result_text += f"  - å®ä½“{i}: {entity.get('name', 'N/A')} (ç›¸ä¼¼åº¦: {similarity})\n"
    
    # å›¾è°±æœç´¢ç»“æœ
    graph_results = details.get('graph_results', {})
    result_text += f"\nğŸ•¸ï¸ å›¾è°±æœç´¢ç»“æœ:\n"
    result_text += f"  - èŠ‚ç‚¹æ•°é‡: {graph_results.get('total_nodes', 0)}\n"
    result_text += f"  - å…³ç³»æ•°é‡: {graph_results.get('total_relationships', 0)}\n"
    
    for i, node in enumerate(graph_results.get('nodes', [])[:3], 1):
        result_text += f"  - èŠ‚ç‚¹{i}: {node.get('name', 'N/A')}\n"
    
    # æ··åˆæœç´¢ç»Ÿè®¡
    hybrid_results = details.get('hybrid_results', {})
    search_stats = hybrid_results.get('search_stats', {})
    result_text += f"\nğŸ”„ æ··åˆæœç´¢ç»Ÿè®¡:\n"
    
    total_time = search_stats.get('total_time', 'N/A')
    if isinstance(total_time, (int, float)):
        result_text += f"  - æ€»æ£€ç´¢æ—¶é—´: {total_time:.3f}s\n"
    else:
        result_text += f"  - æ€»æ£€ç´¢æ—¶é—´: {total_time}\n"
    
    vector_time = search_stats.get('vector_search_time', 'N/A')
    if isinstance(vector_time, (int, float)):
        result_text += f"  - å‘é‡æœç´¢æ—¶é—´: {vector_time:.3f}s\n"
    else:
        result_text += f"  - å‘é‡æœç´¢æ—¶é—´: {vector_time}\n"
    
    graph_time = search_stats.get('graph_search_time', 'N/A')
    if isinstance(graph_time, (int, float)):
        result_text += f"  - å›¾è°±æœç´¢æ—¶é—´: {graph_time:.3f}s\n"
    else:
        result_text += f"  - å›¾è°±æœç´¢æ—¶é—´: {graph_time}\n"
    
    return result_text

def create_rag_chain(rag_system: ModularRAGSystem):
    """åˆ›å»ºRAGé“¾"""
    
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = RAGRetriever(rag_system)
    
    # åˆ›å»ºLLM
    llm = OllamaLLM()
    
    # åˆ›å»ºæç¤ºè¯æ¨¡æ¿
    prompt_template = PromptTemplate(
        input_variables=["context", "question"],
        template="""åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„çŸ¥è¯†å†…å®¹ï¼Œç®€æ´å‡†ç¡®åœ°å›ç­”é—®é¢˜ã€‚

æ£€ç´¢åˆ°çš„çŸ¥è¯†:
{context}

é—®é¢˜: {question}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†ç»™å‡ºç®€æ´çš„å›ç­”:"""
    )
    
    # æ„å»ºRAGé“¾
    def format_docs(docs):
        return "\n\n".join([doc.page_content for doc in docs])
    
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )
    
    return rag_chain, retriever, prompt_template

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨åŸºäºLangChainçš„RAGç³»ç»Ÿ")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        print("ğŸ“¡ åˆå§‹åŒ–RAGç³»ç»Ÿè¿æ¥...")
        with ModularRAGSystem() as rag_system:
            
            # æ£€æŸ¥è¿æ¥çŠ¶æ€
            stats = rag_system.get_stats()
            print(f"âœ… è¿æ¥çŠ¶æ€:")
            print(f"  - Neo4jèŠ‚ç‚¹æ•°: {stats.get('neo4j_nodes', 0)}")
            print(f"  - Neo4jå…³ç³»æ•°: {stats.get('neo4j_relationships', 0)}")
            print(f"  - Weaviateå®ä½“æ•°: {stats.get('vector_entities', 0)}")
            print(f"  - Weaviateå…³ç³»æ•°: {stats.get('vector_relations', 0)}")
            
            # åˆ›å»ºRAGé“¾
            print("\nğŸ”— æ„å»ºLangChain RAGç®¡é“...")
            rag_chain, retriever, prompt_template = create_rag_chain(rag_system)
            
            # äº¤äº’å¼é—®ç­”
            print("\nğŸ’¬ å¼€å§‹äº¤äº’å¼é—®ç­” (è¾“å…¥ 'quit' é€€å‡º)")
            print("-" * 60)
            
            while True:
                try:
                    # ç”¨æˆ·è¾“å…¥
                    question = input("\nâ“ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                    
                    if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                        print("ğŸ‘‹ å†è§ï¼")
                        break
                    
                    if not question:
                        print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜")
                        continue
                    
                    print(f"\nğŸ”„ å¤„ç†é—®é¢˜: {question}")
                    start_time = time.time()
                    
                    # æ‰§è¡ŒRAGé“¾
                    answer = rag_chain.invoke(question)
                    
                    processing_time = time.time() - start_time
                    
                    # å±•ç¤ºç»“æœ
                    print("\n" + "=" * 80)
                    print("ğŸ“‹ å®Œæ•´å¤„ç†ç»“æœ")
                    print("=" * 80)
                    
                    # 1. æ£€ç´¢è¯¦æƒ…
                    print(format_retrieval_results(retriever))
                    
                    # 2. æ„å»ºçš„æç¤ºè¯
                    print(f"\nğŸ“ æ„å»ºçš„æç¤ºè¯:")
                    print("-" * 40)
                    context_docs = retriever._get_relevant_documents(question)
                    context = "\n\n".join([doc.page_content for doc in context_docs])
                    final_prompt = prompt_template.format(context=context, question=question)
                    print(final_prompt[:500] + "..." if len(final_prompt) > 500 else final_prompt)
                    
                    # 3. å¤§æ¨¡å‹å›ç­”
                    print(f"\nğŸ¤– å¤§æ¨¡å‹å›ç­”:")
                    print("-" * 40)
                    print(answer)
                    
                    # 4. å¤„ç†ç»Ÿè®¡
                    print(f"\nâ±ï¸ å¤„ç†ç»Ÿè®¡:")
                    print(f"  - æ€»å¤„ç†æ—¶é—´: {processing_time:.3f}s")
                    print(f"  - æ£€ç´¢æ–‡æ¡£æ•°: {len(context_docs)}")
                    
                    print("\n" + "=" * 80)
                    
                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                    break
                except Exception as e:
                    print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
                    continue
    
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()