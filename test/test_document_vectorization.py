#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£å‘é‡åŒ–å’Œæ£€ç´¢æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–°çš„æ–‡æœ¬å¤„ç†å’Œæ£€ç´¢æœåŠ¡æ¨¡å—
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.services.text_processing_service import TextProcessingService
from src.services.retrieval_service import RetrievalService
from src.knowledge.vector_storage import WeaviateVectorStore
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_text_processing():
    """æµ‹è¯•æ–‡æœ¬å¤„ç†æœåŠ¡"""
    print("\n" + "="*60)
    print("ğŸ”§ æµ‹è¯•æ–‡æœ¬å¤„ç†æœåŠ¡")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–æ–‡æœ¬å¤„ç†æœåŠ¡
        text_processor = TextProcessingService()
        
        # æµ‹è¯•æ–‡æœ¬æ¸…ç†
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚   åŒ…å«å¤šä½™çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦@#$%ã€‚\n\nè¿˜æœ‰æ¢è¡Œç¬¦ã€‚"
        cleaned_text = text_processor.clean_text(test_text)
        print(f"åŸå§‹æ–‡æœ¬: {test_text}")
        print(f"æ¸…ç†åæ–‡æœ¬: {cleaned_text}")
        
        # æµ‹è¯•å¥å­åˆ†å‰²
        sentences = text_processor.split_text_by_sentences(cleaned_text)
        print(f"åˆ†å‰²å¥å­: {sentences}")
        
        # æµ‹è¯•æ–‡æœ¬åˆ†å—
        long_text = "å¸•é‡‘æ£®ç—…æ˜¯ä¸€ç§æ…¢æ€§ç¥ç»é€€è¡Œæ€§ç–¾ç—…ã€‚" * 20
        chunks = text_processor.chunk_text(long_text, "test_doc")
        print(f"æ–‡æœ¬åˆ†å—: {len(chunks)} ä¸ªå—")
        for i, chunk in enumerate(chunks[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  å—{i+1}: {chunk.content[:50]}...")
        
        print("âœ… æ–‡æœ¬å¤„ç†æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æœ¬å¤„ç†æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_retrieval_service():
    """æµ‹è¯•æ£€ç´¢æœåŠ¡"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•æ£€ç´¢æœåŠ¡")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
        retrieval_service = RetrievalService()
        
        # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        from src.services.retrieval_service import SimilarityCalculator
        calc = SimilarityCalculator()
        
        # æµ‹è¯•å‘é‡
        vec1 = [1.0, 2.0, 3.0]
        vec2 = [2.0, 4.0, 6.0]  # vec1çš„2å€
        vec3 = [1.0, 0.0, 0.0]  # ä¸åŒæ–¹å‘
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        cosine_sim = calc.cosine_similarity(vec1, vec2)
        euclidean_dist = calc.euclidean_distance(vec1, vec2)
        manhattan_dist = calc.manhattan_distance(vec1, vec2)
        dot_product = calc.dot_product_similarity(vec1, vec2)
        
        print(f"å‘é‡1: {vec1}")
        print(f"å‘é‡2: {vec2}")
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim:.4f}")
        print(f"æ¬§æ°è·ç¦»: {euclidean_dist:.4f}")
        print(f"æ›¼å“ˆé¡¿è·ç¦»: {manhattan_dist:.4f}")
        print(f"ç‚¹ç§¯: {dot_product:.4f}")
        
        # æµ‹è¯•ä¸åŒå‘é‡
        cosine_sim2 = calc.cosine_similarity(vec1, vec3)
        euclidean_dist2 = calc.euclidean_distance(vec1, vec3)
        
        print(f"\nå‘é‡1: {vec1}")
        print(f"å‘é‡3: {vec3}")
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim2:.4f}")
        print(f"æ¬§æ°è·ç¦»: {euclidean_dist2:.4f}")
        
        print("âœ… æ£€ç´¢æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ£€ç´¢æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_weaviate_connection():
    """æµ‹è¯•Weaviateè¿æ¥"""
    print("\n" + "="*60)
    print("ğŸ”— æµ‹è¯•Weaviateè¿æ¥")
    print("="*60)
    
    try:
        vector_store = WeaviateVectorStore()
        
        # æµ‹è¯•è¿æ¥
        stats = vector_store.get_stats()
        print(f"Weaviateç»Ÿè®¡: {stats}")
        
        print("âœ… Weaviateè¿æ¥æµ‹è¯•é€šè¿‡")
        return vector_store
        
    except Exception as e:
        print(f"âŒ Weaviateè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return None

def test_document_vectorization(file_path: str):
    """æµ‹è¯•æ–‡æ¡£å‘é‡åŒ–"""
    print("\n" + "="*60)
    print(f"ğŸ“„ æµ‹è¯•æ–‡æ¡£å‘é‡åŒ–: {file_path}")
    print("="*60)
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        
        # åˆå§‹åŒ–æœåŠ¡
        text_processor = TextProcessingService()
        vector_store = WeaviateVectorStore()
        
        # è®¾ç½®Weaviateé›†åˆ
        print("ğŸ—ï¸ è®¾ç½®Weaviateé›†åˆ...")
        setup_success = vector_store.setup_collections()
        if not setup_success:
            print("âŒ Weaviateé›†åˆè®¾ç½®å¤±è´¥")
            return False
        
        # å¤„ç†æ–‡æ¡£
        print(f"ğŸ“– å¼€å§‹å¤„ç†æ–‡æ¡£: {file_path}")
        vector_entities = text_processor.process_document(file_path)
        
        if not vector_entities:
            print("âŒ æ–‡æ¡£å¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆå‘é‡å®ä½“")
            return False
        
        print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(vector_entities)} ä¸ªå‘é‡å®ä½“")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå®ä½“çš„ä¿¡æ¯
        print("\nğŸ“‹ å‰3ä¸ªå‘é‡å®ä½“:")
        for i, entity in enumerate(vector_entities[:3]):
            print(f"  å®ä½“{i+1}:")
            print(f"    åç§°: {entity.name}")
            print(f"    ç±»å‹: {entity.type}")
            print(f"    å†…å®¹é•¿åº¦: {len(entity.source_text)} å­—ç¬¦")
            print(f"    å‘é‡ç»´åº¦: {len(entity.vector) if entity.vector else 0}")
            print(f"    å†…å®¹é¢„è§ˆ: {entity.source_text[:100]}...")
        
        # å­˜å‚¨åˆ°Weaviate
        print("\nğŸ’¾ å­˜å‚¨å‘é‡åˆ°Weaviate...")
        store_success = text_processor.store_to_weaviate(vector_entities, vector_store)
        
        if not store_success:
            print("âŒ å‘é‡å­˜å‚¨å¤±è´¥")
            return False
        
        print("âœ… å‘é‡å­˜å‚¨æˆåŠŸ")
        
        # è·å–å­˜å‚¨ç»Ÿè®¡
        stats = vector_store.get_stats()
        print(f"ğŸ“Š å­˜å‚¨ç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£å‘é‡åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_document_retrieval():
    """æµ‹è¯•æ–‡æ¡£æ£€ç´¢"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•æ–‡æ¡£æ£€ç´¢")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
        retrieval_service = RetrievalService()
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "å¸•é‡‘æ£®ç—…çš„ç—‡çŠ¶",
            "å¸•é‡‘æ£®ç—…çš„æ²»ç–—æ–¹æ³•",
            "ç¥ç»é€€è¡Œæ€§ç–¾ç—…",
            "éœ‡é¢¤å’Œè¿åŠ¨éšœç¢"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: {query}")
            
            # ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
            print("  ğŸ“ ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢:")
            cosine_results = retrieval_service.search_by_cosine(query, limit=3)
            for i, result in enumerate(cosine_results):
                print(f"    {i+1}. åˆ†æ•°: {result.score:.4f}, å†…å®¹: {result.content[:80]}...")
            
            # æ¬§æ°è·ç¦»æœç´¢
            print("  ğŸ“ æ¬§æ°è·ç¦»æœç´¢:")
            euclidean_results = retrieval_service.search_by_euclidean(query, limit=3)
            for i, result in enumerate(euclidean_results):
                print(f"    {i+1}. åˆ†æ•°: {result.score:.4f}, å†…å®¹: {result.content[:80]}...")
            
            # æ··åˆæœç´¢
            print("  ğŸ”€ æ··åˆæœç´¢:")
            hybrid_result = retrieval_service.search_hybrid(query, limit=3)
            for i, result in enumerate(hybrid_result.hybrid_results):
                print(f"    {i+1}. åˆ†æ•°: {result.score:.4f}, å†…å®¹: {result.content[:80]}...")
            
            print(f"  ğŸ“Š ç»Ÿè®¡: {hybrid_result.statistics}")
        
        print("\nâœ… æ–‡æ¡£æ£€ç´¢æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£æ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_distance_comparison():
    """æµ‹è¯•è·ç¦»åº¦é‡æ¯”è¾ƒ"""
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•è·ç¦»åº¦é‡æ¯”è¾ƒ")
    print("="*60)
    
    try:
        retrieval_service = RetrievalService()
        
        query = "å¸•é‡‘æ£®ç—…çš„ä¸»è¦ç—‡çŠ¶"
        print(f"ğŸ” æŸ¥è¯¢: {query}")
        
        # æ¯”è¾ƒä¸åŒè·ç¦»åº¦é‡
        comparison = retrieval_service.compare_distance_metrics(query, limit=5)
        
        print(f"\nğŸ“ˆ æ¯”è¾ƒç»“æœ:")
        print(f"  é‡å ç‡: {comparison['analysis']['overlap_rate']:.2%}")
        print(f"  ä»…ä½™å¼¦ç›¸ä¼¼åº¦: {len(comparison['analysis']['cosine_only'])} ä¸ª")
        print(f"  ä»…æ¬§æ°è·ç¦»: {len(comparison['analysis']['euclidean_only'])} ä¸ª")
        print(f"  å…±åŒç»“æœ: {len(comparison['analysis']['common_results'])} ä¸ª")
        print(f"  æ··åˆç‹¬æœ‰: {len(comparison['analysis']['hybrid_unique'])} ä¸ª")
        
        print("\nâœ… è·ç¦»åº¦é‡æ¯”è¾ƒæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ è·ç¦»åº¦é‡æ¯”è¾ƒæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ–‡æ¡£å‘é‡åŒ–å’Œæ£€ç´¢æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•1: æ–‡æœ¬å¤„ç†æœåŠ¡
    if not test_text_processing():
        return
    
    # æµ‹è¯•2: æ£€ç´¢æœåŠ¡
    if not test_retrieval_service():
        return
    
    # æµ‹è¯•3: Weaviateè¿æ¥
    vector_store = test_weaviate_connection()
    if not vector_store:
        return
    
    # æµ‹è¯•4: æ–‡æ¡£å‘é‡åŒ–
    document_path = "e:/Program/Project/HAG/data/pajinsen.txt"
    if not test_document_vectorization(document_path):
        return
    
    # æµ‹è¯•5: æ–‡æ¡£æ£€ç´¢
    if not test_document_retrieval():
        return
    
    # æµ‹è¯•6: è·ç¦»åº¦é‡æ¯”è¾ƒ
    if not test_distance_comparison():
        return
    
    print("\n" + "="*80)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–‡æ¡£å‘é‡åŒ–å’Œæ£€ç´¢ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
    print("="*80)

if __name__ == "__main__":
    main()