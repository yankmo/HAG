#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•gemma3:4bæ¨¡å‹çš„å®é™…å“åº”
"""

import json
import re
import requests

def test_actual_text_chunk():
    """æµ‹è¯•å®é™…çš„æ–‡æœ¬å—"""
    
    # è¯»å–å®é™…æ–‡ä»¶
    with open("e:/Program/Project/rag-first/data/pajinsen.txt", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åˆ†å—å¤„ç†ï¼ˆæ¨¡æ‹Ÿå®é™…ç¨‹åºçš„åˆ†å—é€»è¾‘ï¼‰
    chunks = split_text(content, 1000)
    
    print(f"æ–‡ä»¶æ€»é•¿åº¦: {len(content)} å­—ç¬¦")
    print(f"åˆ†ä¸º {len(chunks)} ä¸ªå—")
    
    # æµ‹è¯•å‰å‡ ä¸ªå—
    for i, chunk in enumerate(chunks[:3]):
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•ç¬¬ {i+1} ä¸ªå— (é•¿åº¦: {len(chunk)} å­—ç¬¦)")
        print(f"{'='*50}")
        print("å—å†…å®¹é¢„è§ˆ:")
        print(chunk[:200] + "..." if len(chunk) > 200 else chunk)
        print(f"{'='*50}")
        
        # å‘é€åˆ°æ¨¡å‹
        response = test_ollama_with_chunk(chunk)
        if response:
            print("âœ… æˆåŠŸè·å¾—å“åº”")
            # æµ‹è¯•è§£æ
            parsed = parse_response(response)
            if parsed:
                print(f"âœ… è§£ææˆåŠŸ: {len(parsed.get('entities', []))} ä¸ªå®ä½“, {len(parsed.get('relations', []))} ä¸ªå…³ç³»")
            else:
                print("âŒ è§£æå¤±è´¥")
        else:
            print("âŒ æœªè·å¾—å“åº”")

def split_text(text: str, chunk_size: int):
    """åˆ†å‰²æ–‡æœ¬ï¼ˆä¸ä¸»ç¨‹åºç›¸åŒçš„é€»è¾‘ï¼‰"""
    paragraphs = text.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) <= chunk_size:
            current_chunk += paragraph + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = paragraph + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def test_ollama_with_chunk(text_chunk):
    """æµ‹è¯•Ollamaå“åº”"""
    url = "http://localhost:11434/api/generate"
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦çŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»åŒ»å­¦æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºç»“æœï¼š
{
    "entities": [
        {
            "name": "å®ä½“åç§°",
            "type": "å®ä½“ç±»å‹",
            "properties": {"description": "å®ä½“æè¿°"}
        }
    ],
    "relations": [
        {
            "source": "æºå®ä½“åç§°",
            "target": "ç›®æ ‡å®ä½“åç§°", 
            "relation_type": "å…³ç³»ç±»å‹",
            "properties": {"description": "å…³ç³»æè¿°"}
        }
    ]
}

å®ä½“ç±»å‹åŒ…æ‹¬ï¼šDisease(ç–¾ç—…), Symptom(ç—‡çŠ¶), Treatment(æ²»ç–—), Drug(è¯ç‰©), Gene(åŸºå› ), Protein(è›‹ç™½è´¨), BodyPart(èº«ä½“éƒ¨ä½), Cause(ç—…å› ), Risk(é£é™©å› ç´ )

å…³ç³»ç±»å‹åŒ…æ‹¬ï¼šCAUSES(å¯¼è‡´), TREATS(æ²»ç–—), HAS_SYMPTOM(æœ‰ç—‡çŠ¶), AFFECTS(å½±å“), RELATED_TO(ç›¸å…³), LOCATED_IN(ä½äº), INCREASES_RISK(å¢åŠ é£é™©), DECREASES_RISK(é™ä½é£é™©)

è¯·ç¡®ä¿è¾“å‡ºçš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""

    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹åŒ»å­¦æ–‡æœ¬ï¼Œæå–å…¶ä¸­çš„å®ä½“å’Œå…³ç³»ï¼š

{text_chunk}

è¯·æå–æ–‡æœ¬ä¸­çš„å…³é”®åŒ»å­¦å®ä½“å’Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ã€‚"""

    data = {
        "model": "gemma3:4b",
        "prompt": user_prompt,
        "system": system_prompt,
        "stream": False,
        "options": {
            "temperature": 0.1,
            "top_p": 0.9,
            "num_predict": 2048
        }
    }
    
    try:
        print("ğŸ”„ å‘é€è¯·æ±‚åˆ°Ollama...")
        response = requests.post(url, json=data, timeout=120)
        response.raise_for_status()
        result = response.json()
        raw_response = result.get("response", "")
        
        print("ğŸ“ åŸå§‹å“åº”:")
        print("-" * 30)
        print(raw_response)
        print("-" * 30)
        
        return raw_response
        
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None

def parse_response(response: str):
    """è§£æå“åº”ï¼ˆä¸ä¸»ç¨‹åºç›¸åŒçš„é€»è¾‘ï¼‰"""
    try:
        cleaned_response = response.strip()
        
        # æ–¹æ³•1: ç›´æ¥è§£æ
        if cleaned_response.startswith('{') and cleaned_response.endswith('}'):
            try:
                json_data = json.loads(cleaned_response)
                if "entities" in json_data or "relations" in json_data:
                    print(f"âœ… ç›´æ¥è§£ææˆåŠŸ")
                    return json_data
            except json.JSONDecodeError as e:
                print(f"âŒ ç›´æ¥è§£æå¤±è´¥: {e}")
        
        # æ–¹æ³•2: æŸ¥æ‰¾```jsonä»£ç å—
        json_pattern = r'```json\s*(\{.*?\})\s*```'
        matches = re.findall(json_pattern, cleaned_response, re.DOTALL | re.IGNORECASE)
        for match in matches:
            try:
                json_str = match.strip()
                json_data = json.loads(json_str)
                if "entities" in json_data or "relations" in json_data:
                    print(f"âœ… æ­£åˆ™è§£ææˆåŠŸ")
                    return json_data
            except json.JSONDecodeError as e:
                print(f"âŒ æ­£åˆ™è§£æå¤±è´¥: {e}")
                continue
        
        # æ–¹æ³•3: æ‰‹åŠ¨æå–
        start_idx = cleaned_response.find('```json')
        if start_idx != -1:
            content_start = start_idx + 7  # len('```json')
            end_idx = cleaned_response.find('```', content_start)
            if end_idx != -1:
                json_str = cleaned_response[content_start:end_idx].strip()
                try:
                    json_data = json.loads(json_str)
                    if "entities" in json_data or "relations" in json_data:
                        print(f"âœ… æ‰‹åŠ¨æå–æˆåŠŸ")
                        return json_data
                except json.JSONDecodeError as e:
                    print(f"âŒ æ‰‹åŠ¨æå–å¤±è´¥: {e}")
        
        # æ–¹æ³•4: æŸ¥æ‰¾ä»»ä½•JSONå¯¹è±¡
        start_idx = cleaned_response.find('{')
        if start_idx != -1:
            end_idx = cleaned_response.rfind('}')
            if end_idx != -1 and end_idx > start_idx:
                json_str = cleaned_response[start_idx:end_idx+1]
                try:
                    json_data = json.loads(json_str)
                    if "entities" in json_data or "relations" in json_data:
                        print(f"âœ… é€šç”¨æå–æˆåŠŸ")
                        return json_data
                except json.JSONDecodeError as e:
                    print(f"âŒ é€šç”¨æå–å¤±è´¥: {e}")
        
        print("âŒ æ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±è´¥äº†")
        return None
        
    except Exception as e:
        print(f"âŒ è§£æå¼‚å¸¸: {e}")
        return None

if __name__ == "__main__":
    test_actual_text_chunk()